{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler,StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(df):\n",
    "    # 説明変数とラベルの分離\n",
    "    label_df = df['dengue']\n",
    "    df = df.drop('dengue', axis=1)\n",
    "\n",
    "    # もとのdfの標準化\n",
    "    numerical_columns = df.columns.tolist()\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_columns)])\n",
    "    df_normalized = preprocessor.fit_transform(df)\n",
    "    df = pd.DataFrame(df_normalized, columns=numerical_columns)  # カラム名を維持\n",
    "\n",
    "    # 特徴量の格納用DataFrame\n",
    "    features_df = pd.DataFrame()\n",
    "\n",
    "    # クラスタリング\n",
    "    kmeans = KMeans(n_clusters=5, random_state=0).fit(df)\n",
    "    features_df['kmeans_dist'] = kmeans.transform(df).min(axis=1)\n",
    "    features_df['kmeans_cluster'] = kmeans.labels_\n",
    "    \n",
    "\n",
    "    dbscan = DBSCAN(eps=0.1, min_samples=1).fit(df)\n",
    "    features_df['dbscan_cluster'] = dbscan.labels_\n",
    "\n",
    "    # 次元削減\n",
    "    pca = PCA(n_components=2, random_state=0)\n",
    "    pca_features = pca.fit_transform(df)\n",
    "    features_df['pca_1'] = pca_features[:, 0]\n",
    "    features_df['pca_2'] = pca_features[:, 1]\n",
    "    \n",
    "    \n",
    "    # 異常検知\n",
    "    isolation_forest = IsolationForest(contamination=0.1, random_state=0)\n",
    "    features_df['anomaly_score'] = isolation_forest.fit_predict(df)\n",
    "\n",
    "    # 距離・類似度ベース\n",
    "    cos_sim_matrix = cosine_similarity(df)\n",
    "    nearest_distances = cos_sim_matrix.mean(axis=1)\n",
    "    features_df['nearest_cosine_similarity'] = nearest_distances\n",
    "    \n",
    "    #学習用dfの正規化\n",
    "    numerical_columns = features_df.columns.tolist()\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', MinMaxScaler())])\n",
    "    preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_columns)])\n",
    "    df_normalized = preprocessor.fit_transform(features_df)\n",
    "    features_df = pd.DataFrame(df_normalized, columns=numerical_columns)  # カラム名を維持\n",
    "\n",
    "    # 学習用データフレームの統合\n",
    "    learning_df = pd.concat([features_df, label_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "    return learning_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract2(df):\n",
    "    # 説明変数とラベルの分離\n",
    "    label_df = df['dengue']\n",
    "    df = df.drop('dengue', axis=1)\n",
    "\n",
    "    # もとのdfの標準化\n",
    "    numerical_columns = df.columns.tolist()\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_columns)])\n",
    "    df_normalized = preprocessor.fit_transform(df)\n",
    "    df_normal = pd.DataFrame(df_normalized, columns=numerical_columns)  # カラム名を維持\n",
    "\n",
    "    # 特徴量の格納用DataFrame\n",
    "    features_df = pd.DataFrame()\n",
    "\n",
    "    # クラスタリング\n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(df_normal)\n",
    "    features_df['kmeans_dist'] = kmeans.transform(df_normal).min(axis=1)\n",
    "    features_df['kmeans_cluster'] = kmeans.labels_\n",
    "    \n",
    "\n",
    "    dbscan = DBSCAN(eps=0.1, min_samples=1).fit(df_normal)\n",
    "    features_df['dbscan_cluster'] = dbscan.labels_\n",
    "\n",
    "    # 次元削減\n",
    "    pca = PCA(n_components=4, random_state=0)\n",
    "    pca_features = pca.fit_transform(df_normal)\n",
    "    features_df['pca_1'] = pca_features[:, 0]\n",
    "    features_df['pca_2'] = pca_features[:, 1]\n",
    "    features_df['pca_3'] = pca_features[:, 2]\n",
    "    features_df['pca_4'] = pca_features[:, 3]\n",
    "    \n",
    "    # 異常検知\n",
    "    isolation_forest = IsolationForest(contamination=0.1, random_state=0)\n",
    "    features_df['anomaly_score'] = isolation_forest.fit_predict(df_normal)\n",
    "\n",
    "    # 距離・類似度ベース\n",
    "    cos_sim_matrix = cosine_similarity(df_normal)\n",
    "    nearest_distances = cos_sim_matrix.mean(axis=1)\n",
    "    features_df['nearest_cosine_similarity'] = nearest_distances\n",
    "    \n",
    "    #学習用dfの正規化\n",
    "    numerical_columns = features_df.columns.tolist()\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', MinMaxScaler())])\n",
    "    preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_columns)])\n",
    "    df_normalized = preprocessor.fit_transform(features_df)\n",
    "    features_df = pd.DataFrame(df_normalized, columns=numerical_columns)  # カラム名を維持\n",
    "\n",
    "    # 学習用データフレームの統合\n",
    "    learning_df = pd.concat([df,features_df, label_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "    return learning_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('../data/preprocessed_data/df1.csv',index_col=0)\n",
    "df2=pd.read_csv('../data/preprocessed_data/df2.csv',index_col=0)\n",
    "df3=pd.read_csv('../data/preprocessed_data/df3.csv',index_col=0)\n",
    "df4=pd.read_csv('../data/preprocessed_data/df4.csv',index_col=0)\n",
    "df5=pd.read_csv('../data/preprocessed_data/df5.csv',index_col=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df1=feature_extract(df1)\n",
    "learning_df2=feature_extract(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df=pd.concat([learning_df1,learning_df2],axis=0)\n",
    "learning_df.to_csv('../data/learning_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kmeans_dist</th>\n",
       "      <th>kmeans_cluster</th>\n",
       "      <th>dbscan_cluster</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>nearest_cosine_similarity</th>\n",
       "      <th>dengue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.807903</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690117</td>\n",
       "      <td>0.530614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.248749</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.872944</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.548990</td>\n",
       "      <td>0.361146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.372575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.811521</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.402503</td>\n",
       "      <td>0.733854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.528842</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.809303</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.472950</td>\n",
       "      <td>0.346633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.815355</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.601353</td>\n",
       "      <td>0.324567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.329382</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.179921</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766380</td>\n",
       "      <td>0.234948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.410607</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.123779</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.942497</td>\n",
       "      <td>0.030640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622803</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.216380</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.757859</td>\n",
       "      <td>0.355427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.202073</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.093152</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.693195</td>\n",
       "      <td>0.077580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0.151205</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.375804</td>\n",
       "      <td>0.031293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4386 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     kmeans_dist  kmeans_cluster  dbscan_cluster     pca_1     pca_2  \\\n",
       "0       0.807903            1.00        0.000000  0.690117  0.530614   \n",
       "1       0.872944            0.25        0.000378  0.548990  0.361146   \n",
       "2       0.811521            0.00        0.000755  0.402503  0.733854   \n",
       "3       0.809303            1.00        0.001133  0.472950  0.346633   \n",
       "4       0.815355            0.00        0.001511  0.601353  0.324567   \n",
       "..           ...             ...             ...       ...       ...   \n",
       "408     0.179921            0.75        1.000000  0.766380  0.234948   \n",
       "409     0.123779            0.75        0.656863  0.942497  0.030640   \n",
       "410     0.216380            0.75        0.794118  0.757859  0.355427   \n",
       "411     0.093152            0.75        0.196078  0.693195  0.077580   \n",
       "412     0.151205            0.00        0.352941  0.375804  0.031293   \n",
       "\n",
       "     anomaly_score  nearest_cosine_similarity  dengue  \n",
       "0              1.0                   0.248749     1.0  \n",
       "1              1.0                   0.372575     0.0  \n",
       "2              1.0                   0.528842     0.0  \n",
       "3              0.0                   0.441506     0.0  \n",
       "4              1.0                   0.329382     1.0  \n",
       "..             ...                        ...     ...  \n",
       "408            1.0                   0.410607     0.0  \n",
       "409            1.0                   0.622803     0.0  \n",
       "410            1.0                   0.202073     1.0  \n",
       "411            1.0                   0.881248     0.0  \n",
       "412            1.0                   0.235000     1.0  \n",
       "\n",
       "[4386 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
