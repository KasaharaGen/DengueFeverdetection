{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-17T09:48:10.434701Z",
     "start_time": "2024-10-17T09:48:10.428736Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:48:10.666660Z",
     "start_time": "2024-10-17T09:48:10.652909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# データの読み込み\n",
    "data = pd.read_csv('../../data/preprocessed_data.csv')\n",
    "\n",
    "# 特徴量とターゲット変数の分割,DFのvalueのみ抽出\n",
    "X = data.drop('dengue', axis=1).values  \n",
    "y = data['dengue'].values"
   ],
   "id": "ff22be936da9b0d7",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:48:11.149979Z",
     "start_time": "2024-10-17T09:48:11.143171Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)",
   "id": "ddfea19e880328ae",
   "outputs": [],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:48:11.533775Z",
     "start_time": "2024-10-17T09:48:11.527233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#numpy配列をtensolに変換\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ],
   "id": "aee0ed7624db22a3",
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:48:12.065659Z",
     "start_time": "2024-10-17T09:48:12.059464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TensorDatasetの作成\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ],
   "id": "af0aaa78566c4f15",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:48:14.493287Z",
     "start_time": "2024-10-17T09:48:14.485068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ニューラルネットワークの定義\n",
    "class ClassificationNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ClassificationNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,64)  \n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)           \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))         \n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))      \n",
    "        return x\n"
   ],
   "id": "c5388a07a2c78506",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:49:22.753117Z",
     "start_time": "2024-10-17T09:49:22.744563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# モデルの初期化\n",
    "input_size = X_train_tensor.shape[1]  \n",
    "model = ClassificationNN(input_size)\n",
    "\n",
    "# 損失関数と最適化手法の設定\n",
    "criterion = nn.BCELoss()  # バイナリクロスエントロピー損失関数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "id": "47f5180a2c8b5c61",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:50:08.535110Z",
     "start_time": "2024-10-17T09:50:02.968180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 訓練モード\n",
    "\n",
    "    # 順伝播\n",
    "    outputs = model(X_train_tensor)\n",
    "\n",
    "    # 損失計算\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # 勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 逆伝播とパラメータ更新\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 精度（accuracy）の計算\n",
    "    predicted = outputs.round()  # 0.5以上の予測値は1、それ以外は0に丸める\n",
    "    correct = (predicted == y_train_tensor).float().sum().item()\n",
    "    accuracy = correct / y_train_tensor.size(0) * 100  # 全サンプル数に対する正解率\n",
    "\n",
    "    # 10エポックごとに損失と精度を表示\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')\n"
   ],
   "id": "a4628378dfda5182",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/2000], Loss: 0.1385, Accuracy: 94.23%\n",
      "Epoch [20/2000], Loss: 0.1382, Accuracy: 94.23%\n",
      "Epoch [30/2000], Loss: 0.1380, Accuracy: 94.23%\n",
      "Epoch [40/2000], Loss: 0.1379, Accuracy: 94.30%\n",
      "Epoch [50/2000], Loss: 0.1374, Accuracy: 94.23%\n",
      "Epoch [60/2000], Loss: 0.1370, Accuracy: 94.30%\n",
      "Epoch [70/2000], Loss: 0.1366, Accuracy: 94.23%\n",
      "Epoch [80/2000], Loss: 0.1363, Accuracy: 94.23%\n",
      "Epoch [90/2000], Loss: 0.1361, Accuracy: 94.30%\n",
      "Epoch [100/2000], Loss: 0.1359, Accuracy: 94.27%\n",
      "Epoch [110/2000], Loss: 0.1357, Accuracy: 94.30%\n",
      "Epoch [120/2000], Loss: 0.1354, Accuracy: 94.27%\n",
      "Epoch [130/2000], Loss: 0.1352, Accuracy: 94.30%\n",
      "Epoch [140/2000], Loss: 0.1350, Accuracy: 94.27%\n",
      "Epoch [150/2000], Loss: 0.1345, Accuracy: 94.30%\n",
      "Epoch [160/2000], Loss: 0.1341, Accuracy: 94.33%\n",
      "Epoch [170/2000], Loss: 0.1340, Accuracy: 94.30%\n",
      "Epoch [180/2000], Loss: 0.1336, Accuracy: 94.33%\n",
      "Epoch [190/2000], Loss: 0.1333, Accuracy: 94.30%\n",
      "Epoch [200/2000], Loss: 0.1331, Accuracy: 94.33%\n",
      "Epoch [210/2000], Loss: 0.1329, Accuracy: 94.30%\n",
      "Epoch [220/2000], Loss: 0.1328, Accuracy: 94.33%\n",
      "Epoch [230/2000], Loss: 0.1324, Accuracy: 94.30%\n",
      "Epoch [240/2000], Loss: 0.1320, Accuracy: 94.33%\n",
      "Epoch [250/2000], Loss: 0.1317, Accuracy: 94.30%\n",
      "Epoch [260/2000], Loss: 0.1315, Accuracy: 94.33%\n",
      "Epoch [270/2000], Loss: 0.1312, Accuracy: 94.30%\n",
      "Epoch [280/2000], Loss: 0.1309, Accuracy: 94.33%\n",
      "Epoch [290/2000], Loss: 0.1306, Accuracy: 94.33%\n",
      "Epoch [300/2000], Loss: 0.1306, Accuracy: 94.33%\n",
      "Epoch [310/2000], Loss: 0.1304, Accuracy: 94.33%\n",
      "Epoch [320/2000], Loss: 0.1302, Accuracy: 94.33%\n",
      "Epoch [330/2000], Loss: 0.1300, Accuracy: 94.36%\n",
      "Epoch [340/2000], Loss: 0.1297, Accuracy: 94.33%\n",
      "Epoch [350/2000], Loss: 0.1294, Accuracy: 94.33%\n",
      "Epoch [360/2000], Loss: 0.1290, Accuracy: 94.36%\n",
      "Epoch [370/2000], Loss: 0.1287, Accuracy: 94.36%\n",
      "Epoch [380/2000], Loss: 0.1284, Accuracy: 94.36%\n",
      "Epoch [390/2000], Loss: 0.1282, Accuracy: 94.36%\n",
      "Epoch [400/2000], Loss: 0.1281, Accuracy: 94.40%\n",
      "Epoch [410/2000], Loss: 0.1279, Accuracy: 94.36%\n",
      "Epoch [420/2000], Loss: 0.1276, Accuracy: 94.40%\n",
      "Epoch [430/2000], Loss: 0.1275, Accuracy: 94.40%\n",
      "Epoch [440/2000], Loss: 0.1274, Accuracy: 94.40%\n",
      "Epoch [450/2000], Loss: 0.1272, Accuracy: 94.43%\n",
      "Epoch [460/2000], Loss: 0.1269, Accuracy: 94.40%\n",
      "Epoch [470/2000], Loss: 0.1266, Accuracy: 94.43%\n",
      "Epoch [480/2000], Loss: 0.1263, Accuracy: 94.40%\n",
      "Epoch [490/2000], Loss: 0.1261, Accuracy: 94.43%\n",
      "Epoch [500/2000], Loss: 0.1256, Accuracy: 94.43%\n",
      "Epoch [510/2000], Loss: 0.1254, Accuracy: 94.43%\n",
      "Epoch [520/2000], Loss: 0.1251, Accuracy: 94.46%\n",
      "Epoch [530/2000], Loss: 0.1249, Accuracy: 94.43%\n",
      "Epoch [540/2000], Loss: 0.1247, Accuracy: 94.46%\n",
      "Epoch [550/2000], Loss: 0.1245, Accuracy: 94.46%\n",
      "Epoch [560/2000], Loss: 0.1243, Accuracy: 94.46%\n",
      "Epoch [570/2000], Loss: 0.1241, Accuracy: 94.46%\n",
      "Epoch [580/2000], Loss: 0.1238, Accuracy: 94.46%\n",
      "Epoch [590/2000], Loss: 0.1237, Accuracy: 94.46%\n",
      "Epoch [600/2000], Loss: 0.1234, Accuracy: 94.50%\n",
      "Epoch [610/2000], Loss: 0.1232, Accuracy: 94.46%\n",
      "Epoch [620/2000], Loss: 0.1230, Accuracy: 94.46%\n",
      "Epoch [630/2000], Loss: 0.1228, Accuracy: 94.50%\n",
      "Epoch [640/2000], Loss: 0.1226, Accuracy: 94.50%\n",
      "Epoch [650/2000], Loss: 0.1225, Accuracy: 94.50%\n",
      "Epoch [660/2000], Loss: 0.1223, Accuracy: 94.50%\n",
      "Epoch [670/2000], Loss: 0.1221, Accuracy: 94.50%\n",
      "Epoch [680/2000], Loss: 0.1219, Accuracy: 94.50%\n",
      "Epoch [690/2000], Loss: 0.1217, Accuracy: 94.50%\n",
      "Epoch [700/2000], Loss: 0.1217, Accuracy: 94.50%\n",
      "Epoch [710/2000], Loss: 0.1217, Accuracy: 94.50%\n",
      "Epoch [720/2000], Loss: 0.1213, Accuracy: 94.53%\n",
      "Epoch [730/2000], Loss: 0.1211, Accuracy: 94.53%\n",
      "Epoch [740/2000], Loss: 0.1208, Accuracy: 94.53%\n",
      "Epoch [750/2000], Loss: 0.1206, Accuracy: 94.53%\n",
      "Epoch [760/2000], Loss: 0.1204, Accuracy: 94.53%\n",
      "Epoch [770/2000], Loss: 0.1202, Accuracy: 94.56%\n",
      "Epoch [780/2000], Loss: 0.1202, Accuracy: 94.53%\n",
      "Epoch [790/2000], Loss: 0.1202, Accuracy: 94.59%\n",
      "Epoch [800/2000], Loss: 0.1201, Accuracy: 94.53%\n",
      "Epoch [810/2000], Loss: 0.1199, Accuracy: 94.59%\n",
      "Epoch [820/2000], Loss: 0.1197, Accuracy: 94.53%\n",
      "Epoch [830/2000], Loss: 0.1193, Accuracy: 94.59%\n",
      "Epoch [840/2000], Loss: 0.1191, Accuracy: 94.53%\n",
      "Epoch [850/2000], Loss: 0.1188, Accuracy: 94.56%\n",
      "Epoch [860/2000], Loss: 0.1187, Accuracy: 94.59%\n",
      "Epoch [870/2000], Loss: 0.1188, Accuracy: 94.53%\n",
      "Epoch [880/2000], Loss: 0.1185, Accuracy: 94.59%\n",
      "Epoch [890/2000], Loss: 0.1182, Accuracy: 94.56%\n",
      "Epoch [900/2000], Loss: 0.1180, Accuracy: 94.59%\n",
      "Epoch [910/2000], Loss: 0.1178, Accuracy: 94.59%\n",
      "Epoch [920/2000], Loss: 0.1176, Accuracy: 94.59%\n",
      "Epoch [930/2000], Loss: 0.1174, Accuracy: 94.59%\n",
      "Epoch [940/2000], Loss: 0.1173, Accuracy: 94.56%\n",
      "Epoch [950/2000], Loss: 0.1173, Accuracy: 94.63%\n",
      "Epoch [960/2000], Loss: 0.1172, Accuracy: 94.56%\n",
      "Epoch [970/2000], Loss: 0.1171, Accuracy: 94.63%\n",
      "Epoch [980/2000], Loss: 0.1169, Accuracy: 94.56%\n",
      "Epoch [990/2000], Loss: 0.1167, Accuracy: 94.63%\n",
      "Epoch [1000/2000], Loss: 0.1166, Accuracy: 94.56%\n",
      "Epoch [1010/2000], Loss: 0.1163, Accuracy: 94.63%\n",
      "Epoch [1020/2000], Loss: 0.1162, Accuracy: 94.59%\n",
      "Epoch [1030/2000], Loss: 0.1161, Accuracy: 94.63%\n",
      "Epoch [1040/2000], Loss: 0.1159, Accuracy: 94.59%\n",
      "Epoch [1050/2000], Loss: 0.1157, Accuracy: 94.63%\n",
      "Epoch [1060/2000], Loss: 0.1155, Accuracy: 94.59%\n",
      "Epoch [1070/2000], Loss: 0.1154, Accuracy: 94.63%\n",
      "Epoch [1080/2000], Loss: 0.1152, Accuracy: 94.59%\n",
      "Epoch [1090/2000], Loss: 0.1151, Accuracy: 94.63%\n",
      "Epoch [1100/2000], Loss: 0.1149, Accuracy: 94.59%\n",
      "Epoch [1110/2000], Loss: 0.1147, Accuracy: 94.63%\n",
      "Epoch [1120/2000], Loss: 0.1148, Accuracy: 94.63%\n",
      "Epoch [1130/2000], Loss: 0.1149, Accuracy: 94.59%\n",
      "Epoch [1140/2000], Loss: 0.1147, Accuracy: 94.63%\n",
      "Epoch [1150/2000], Loss: 0.1146, Accuracy: 94.59%\n",
      "Epoch [1160/2000], Loss: 0.1145, Accuracy: 94.63%\n",
      "Epoch [1170/2000], Loss: 0.1142, Accuracy: 94.59%\n",
      "Epoch [1180/2000], Loss: 0.1139, Accuracy: 94.63%\n",
      "Epoch [1190/2000], Loss: 0.1136, Accuracy: 94.63%\n",
      "Epoch [1200/2000], Loss: 0.1135, Accuracy: 94.63%\n",
      "Epoch [1210/2000], Loss: 0.1135, Accuracy: 94.63%\n",
      "Epoch [1220/2000], Loss: 0.1134, Accuracy: 94.59%\n",
      "Epoch [1230/2000], Loss: 0.1135, Accuracy: 94.63%\n",
      "Epoch [1240/2000], Loss: 0.1134, Accuracy: 94.59%\n",
      "Epoch [1250/2000], Loss: 0.1132, Accuracy: 94.63%\n",
      "Epoch [1260/2000], Loss: 0.1129, Accuracy: 94.59%\n",
      "Epoch [1270/2000], Loss: 0.1126, Accuracy: 94.63%\n",
      "Epoch [1280/2000], Loss: 0.1130, Accuracy: 94.63%\n",
      "Epoch [1290/2000], Loss: 0.1127, Accuracy: 94.59%\n",
      "Epoch [1300/2000], Loss: 0.1124, Accuracy: 94.63%\n",
      "Epoch [1310/2000], Loss: 0.1121, Accuracy: 94.63%\n",
      "Epoch [1320/2000], Loss: 0.1120, Accuracy: 94.63%\n",
      "Epoch [1330/2000], Loss: 0.1122, Accuracy: 94.63%\n",
      "Epoch [1340/2000], Loss: 0.1121, Accuracy: 94.59%\n",
      "Epoch [1350/2000], Loss: 0.1117, Accuracy: 94.63%\n",
      "Epoch [1360/2000], Loss: 0.1116, Accuracy: 94.63%\n",
      "Epoch [1370/2000], Loss: 0.1118, Accuracy: 94.59%\n",
      "Epoch [1380/2000], Loss: 0.1116, Accuracy: 94.63%\n",
      "Epoch [1390/2000], Loss: 0.1112, Accuracy: 94.63%\n",
      "Epoch [1400/2000], Loss: 0.1111, Accuracy: 94.63%\n",
      "Epoch [1410/2000], Loss: 0.1113, Accuracy: 94.63%\n",
      "Epoch [1420/2000], Loss: 0.1112, Accuracy: 94.63%\n",
      "Epoch [1430/2000], Loss: 0.1108, Accuracy: 94.63%\n",
      "Epoch [1440/2000], Loss: 0.1106, Accuracy: 94.63%\n",
      "Epoch [1450/2000], Loss: 0.1106, Accuracy: 94.63%\n",
      "Epoch [1460/2000], Loss: 0.1108, Accuracy: 94.63%\n",
      "Epoch [1470/2000], Loss: 0.1108, Accuracy: 94.63%\n",
      "Epoch [1480/2000], Loss: 0.1105, Accuracy: 94.63%\n",
      "Epoch [1490/2000], Loss: 0.1103, Accuracy: 94.63%\n",
      "Epoch [1500/2000], Loss: 0.1100, Accuracy: 94.63%\n",
      "Epoch [1510/2000], Loss: 0.1099, Accuracy: 94.63%\n",
      "Epoch [1520/2000], Loss: 0.1098, Accuracy: 94.63%\n",
      "Epoch [1530/2000], Loss: 0.1100, Accuracy: 94.63%\n",
      "Epoch [1540/2000], Loss: 0.1100, Accuracy: 94.66%\n",
      "Epoch [1550/2000], Loss: 0.1098, Accuracy: 94.63%\n",
      "Epoch [1560/2000], Loss: 0.1096, Accuracy: 94.66%\n",
      "Epoch [1570/2000], Loss: 0.1094, Accuracy: 94.63%\n",
      "Epoch [1580/2000], Loss: 0.1092, Accuracy: 94.63%\n",
      "Epoch [1590/2000], Loss: 0.1091, Accuracy: 94.63%\n",
      "Epoch [1600/2000], Loss: 0.1090, Accuracy: 94.63%\n",
      "Epoch [1610/2000], Loss: 0.1089, Accuracy: 94.63%\n",
      "Epoch [1620/2000], Loss: 0.1090, Accuracy: 94.63%\n",
      "Epoch [1630/2000], Loss: 0.1091, Accuracy: 94.66%\n",
      "Epoch [1640/2000], Loss: 0.1088, Accuracy: 94.63%\n",
      "Epoch [1650/2000], Loss: 0.1086, Accuracy: 94.66%\n",
      "Epoch [1660/2000], Loss: 0.1084, Accuracy: 94.63%\n",
      "Epoch [1670/2000], Loss: 0.1083, Accuracy: 94.63%\n",
      "Epoch [1680/2000], Loss: 0.1084, Accuracy: 94.66%\n",
      "Epoch [1690/2000], Loss: 0.1084, Accuracy: 94.63%\n",
      "Epoch [1700/2000], Loss: 0.1081, Accuracy: 94.66%\n",
      "Epoch [1710/2000], Loss: 0.1080, Accuracy: 94.66%\n",
      "Epoch [1720/2000], Loss: 0.1080, Accuracy: 94.63%\n",
      "Epoch [1730/2000], Loss: 0.1080, Accuracy: 94.66%\n",
      "Epoch [1740/2000], Loss: 0.1081, Accuracy: 94.63%\n",
      "Epoch [1750/2000], Loss: 0.1080, Accuracy: 94.69%\n",
      "Epoch [1760/2000], Loss: 0.1078, Accuracy: 94.63%\n",
      "Epoch [1770/2000], Loss: 0.1075, Accuracy: 94.66%\n",
      "Epoch [1780/2000], Loss: 0.1074, Accuracy: 94.66%\n",
      "Epoch [1790/2000], Loss: 0.1073, Accuracy: 94.66%\n",
      "Epoch [1800/2000], Loss: 0.1073, Accuracy: 94.66%\n",
      "Epoch [1810/2000], Loss: 0.1074, Accuracy: 94.63%\n",
      "Epoch [1820/2000], Loss: 0.1074, Accuracy: 94.69%\n",
      "Epoch [1830/2000], Loss: 0.1073, Accuracy: 94.63%\n",
      "Epoch [1840/2000], Loss: 0.1071, Accuracy: 94.69%\n",
      "Epoch [1850/2000], Loss: 0.1068, Accuracy: 94.66%\n",
      "Epoch [1860/2000], Loss: 0.1067, Accuracy: 94.66%\n",
      "Epoch [1870/2000], Loss: 0.1069, Accuracy: 94.69%\n",
      "Epoch [1880/2000], Loss: 0.1069, Accuracy: 94.66%\n",
      "Epoch [1890/2000], Loss: 0.1068, Accuracy: 94.69%\n",
      "Epoch [1900/2000], Loss: 0.1065, Accuracy: 94.66%\n",
      "Epoch [1910/2000], Loss: 0.1063, Accuracy: 94.69%\n",
      "Epoch [1920/2000], Loss: 0.1063, Accuracy: 94.69%\n",
      "Epoch [1930/2000], Loss: 0.1065, Accuracy: 94.66%\n",
      "Epoch [1940/2000], Loss: 0.1063, Accuracy: 94.69%\n",
      "Epoch [1950/2000], Loss: 0.1060, Accuracy: 94.66%\n",
      "Epoch [1960/2000], Loss: 0.1061, Accuracy: 94.66%\n",
      "Epoch [1970/2000], Loss: 0.1064, Accuracy: 94.69%\n",
      "Epoch [1980/2000], Loss: 0.1062, Accuracy: 94.66%\n",
      "Epoch [1990/2000], Loss: 0.1060, Accuracy: 94.69%\n",
      "Epoch [2000/2000], Loss: 0.1058, Accuracy: 94.66%\n"
     ]
    }
   ],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:44:48.476123Z",
     "start_time": "2024-10-17T09:44:19.809411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#バッチ処理番\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        optimizer.zero_grad()  # 勾配の初期化\n",
    "\n",
    "        # バッチデータを使って順伝播\n",
    "        outputs = model(X_batch)\n",
    "        \n",
    "        # 損失計算\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "        \n",
    "        # 逆伝播とパラメータの更新\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 累積損失の計算\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 精度（accuracy）の計算\n",
    "        predicted = outputs.round()  # 0.5以上は1、未満は0に丸める\n",
    "        correct += (predicted == Y_batch).sum().item()\n",
    "        total += Y_batch.size(0)\n",
    "\n",
    "    # エポックごとの損失と精度を表示\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%')\n"
   ],
   "id": "51c3f6a17268bbc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6884, Accuracy: 55.70%\n",
      "Epoch [2/100], Loss: 0.6762, Accuracy: 58.01%\n",
      "Epoch [3/100], Loss: 0.6616, Accuracy: 60.55%\n",
      "Epoch [4/100], Loss: 0.6456, Accuracy: 62.67%\n",
      "Epoch [5/100], Loss: 0.6314, Accuracy: 63.81%\n",
      "Epoch [6/100], Loss: 0.6204, Accuracy: 63.94%\n",
      "Epoch [7/100], Loss: 0.6120, Accuracy: 64.36%\n",
      "Epoch [8/100], Loss: 0.6053, Accuracy: 64.10%\n",
      "Epoch [9/100], Loss: 0.5990, Accuracy: 64.14%\n",
      "Epoch [10/100], Loss: 0.5930, Accuracy: 64.56%\n",
      "Epoch [11/100], Loss: 0.5880, Accuracy: 64.63%\n",
      "Epoch [12/100], Loss: 0.5821, Accuracy: 64.36%\n",
      "Epoch [13/100], Loss: 0.5775, Accuracy: 64.56%\n",
      "Epoch [14/100], Loss: 0.5729, Accuracy: 65.21%\n",
      "Epoch [15/100], Loss: 0.5688, Accuracy: 65.37%\n",
      "Epoch [16/100], Loss: 0.5653, Accuracy: 65.15%\n",
      "Epoch [17/100], Loss: 0.5618, Accuracy: 65.37%\n",
      "Epoch [18/100], Loss: 0.5588, Accuracy: 65.80%\n",
      "Epoch [19/100], Loss: 0.5559, Accuracy: 66.12%\n",
      "Epoch [20/100], Loss: 0.5534, Accuracy: 65.96%\n",
      "Epoch [21/100], Loss: 0.5513, Accuracy: 66.87%\n",
      "Epoch [22/100], Loss: 0.5493, Accuracy: 66.32%\n",
      "Epoch [23/100], Loss: 0.5477, Accuracy: 67.07%\n",
      "Epoch [24/100], Loss: 0.5461, Accuracy: 67.04%\n",
      "Epoch [25/100], Loss: 0.5443, Accuracy: 66.58%\n",
      "Epoch [26/100], Loss: 0.5431, Accuracy: 66.78%\n",
      "Epoch [27/100], Loss: 0.5423, Accuracy: 66.35%\n",
      "Epoch [28/100], Loss: 0.5411, Accuracy: 66.74%\n",
      "Epoch [29/100], Loss: 0.5400, Accuracy: 66.91%\n",
      "Epoch [30/100], Loss: 0.5394, Accuracy: 66.61%\n",
      "Epoch [31/100], Loss: 0.5382, Accuracy: 67.00%\n",
      "Epoch [32/100], Loss: 0.5375, Accuracy: 67.10%\n",
      "Epoch [33/100], Loss: 0.5369, Accuracy: 66.78%\n",
      "Epoch [34/100], Loss: 0.5359, Accuracy: 67.17%\n",
      "Epoch [35/100], Loss: 0.5354, Accuracy: 67.10%\n",
      "Epoch [36/100], Loss: 0.5347, Accuracy: 66.97%\n",
      "Epoch [37/100], Loss: 0.5342, Accuracy: 66.68%\n",
      "Epoch [38/100], Loss: 0.5331, Accuracy: 66.68%\n",
      "Epoch [39/100], Loss: 0.5326, Accuracy: 67.20%\n",
      "Epoch [40/100], Loss: 0.5319, Accuracy: 67.13%\n",
      "Epoch [41/100], Loss: 0.5312, Accuracy: 67.04%\n",
      "Epoch [42/100], Loss: 0.5309, Accuracy: 67.07%\n",
      "Epoch [43/100], Loss: 0.5306, Accuracy: 66.94%\n",
      "Epoch [44/100], Loss: 0.5297, Accuracy: 67.56%\n",
      "Epoch [45/100], Loss: 0.5294, Accuracy: 67.88%\n",
      "Epoch [46/100], Loss: 0.5286, Accuracy: 67.52%\n",
      "Epoch [47/100], Loss: 0.5279, Accuracy: 67.69%\n",
      "Epoch [48/100], Loss: 0.5278, Accuracy: 67.72%\n",
      "Epoch [49/100], Loss: 0.5271, Accuracy: 67.36%\n",
      "Epoch [50/100], Loss: 0.5267, Accuracy: 67.69%\n",
      "Epoch [51/100], Loss: 0.5262, Accuracy: 68.21%\n",
      "Epoch [52/100], Loss: 0.5258, Accuracy: 67.92%\n",
      "Epoch [53/100], Loss: 0.5253, Accuracy: 67.95%\n",
      "Epoch [54/100], Loss: 0.5246, Accuracy: 68.24%\n",
      "Epoch [55/100], Loss: 0.5244, Accuracy: 67.95%\n",
      "Epoch [56/100], Loss: 0.5236, Accuracy: 68.01%\n",
      "Epoch [57/100], Loss: 0.5236, Accuracy: 67.95%\n",
      "Epoch [58/100], Loss: 0.5227, Accuracy: 68.44%\n",
      "Epoch [59/100], Loss: 0.5227, Accuracy: 68.34%\n",
      "Epoch [60/100], Loss: 0.5219, Accuracy: 67.98%\n",
      "Epoch [61/100], Loss: 0.5213, Accuracy: 68.99%\n",
      "Epoch [62/100], Loss: 0.5212, Accuracy: 68.21%\n",
      "Epoch [63/100], Loss: 0.5208, Accuracy: 68.44%\n",
      "Epoch [64/100], Loss: 0.5205, Accuracy: 68.89%\n",
      "Epoch [65/100], Loss: 0.5200, Accuracy: 69.02%\n",
      "Epoch [66/100], Loss: 0.5192, Accuracy: 68.63%\n",
      "Epoch [67/100], Loss: 0.5189, Accuracy: 68.83%\n",
      "Epoch [68/100], Loss: 0.5185, Accuracy: 68.86%\n",
      "Epoch [69/100], Loss: 0.5180, Accuracy: 69.02%\n",
      "Epoch [70/100], Loss: 0.5177, Accuracy: 68.70%\n",
      "Epoch [71/100], Loss: 0.5173, Accuracy: 69.19%\n",
      "Epoch [72/100], Loss: 0.5169, Accuracy: 69.19%\n",
      "Epoch [73/100], Loss: 0.5163, Accuracy: 69.28%\n",
      "Epoch [74/100], Loss: 0.5156, Accuracy: 69.06%\n",
      "Epoch [75/100], Loss: 0.5155, Accuracy: 69.67%\n",
      "Epoch [76/100], Loss: 0.5155, Accuracy: 69.35%\n",
      "Epoch [77/100], Loss: 0.5148, Accuracy: 69.61%\n",
      "Epoch [78/100], Loss: 0.5140, Accuracy: 69.28%\n",
      "Epoch [79/100], Loss: 0.5141, Accuracy: 69.84%\n",
      "Epoch [80/100], Loss: 0.5135, Accuracy: 69.58%\n",
      "Epoch [81/100], Loss: 0.5130, Accuracy: 70.16%\n",
      "Epoch [82/100], Loss: 0.5123, Accuracy: 70.00%\n",
      "Epoch [83/100], Loss: 0.5121, Accuracy: 69.80%\n",
      "Epoch [84/100], Loss: 0.5116, Accuracy: 70.29%\n",
      "Epoch [85/100], Loss: 0.5114, Accuracy: 70.00%\n",
      "Epoch [86/100], Loss: 0.5106, Accuracy: 70.49%\n",
      "Epoch [87/100], Loss: 0.5106, Accuracy: 70.16%\n",
      "Epoch [88/100], Loss: 0.5100, Accuracy: 70.26%\n",
      "Epoch [89/100], Loss: 0.5097, Accuracy: 70.55%\n",
      "Epoch [90/100], Loss: 0.5092, Accuracy: 70.07%\n",
      "Epoch [91/100], Loss: 0.5085, Accuracy: 70.68%\n",
      "Epoch [92/100], Loss: 0.5081, Accuracy: 70.23%\n",
      "Epoch [93/100], Loss: 0.5081, Accuracy: 70.65%\n",
      "Epoch [94/100], Loss: 0.5075, Accuracy: 70.85%\n",
      "Epoch [95/100], Loss: 0.5068, Accuracy: 70.94%\n",
      "Epoch [96/100], Loss: 0.5068, Accuracy: 71.24%\n",
      "Epoch [97/100], Loss: 0.5059, Accuracy: 70.94%\n",
      "Epoch [98/100], Loss: 0.5057, Accuracy: 70.62%\n",
      "Epoch [99/100], Loss: 0.5055, Accuracy: 70.72%\n",
      "Epoch [100/100], Loss: 0.5046, Accuracy: 71.01%\n"
     ]
    }
   ],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:44:48.576456Z",
     "start_time": "2024-10-17T09:44:48.504452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# テストデータでの評価\n",
    "model.eval()  # 評価モード\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    predictions = predictions.round()  # 出力を0または1に丸める\n",
    "    accuracy = (predictions == y_test_tensor).float().mean()\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n"
   ],
   "id": "cbc7c4b7be72d31f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6436\n"
     ]
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:44:48.610105Z",
     "start_time": "2024-10-17T09:44:48.606643Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4b30c945dafa844b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
