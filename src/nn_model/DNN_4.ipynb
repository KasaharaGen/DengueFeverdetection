{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc,matthews_corrcoef, precision_recall_curve,roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ読み取り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../data/learning_data.csv',index_col=0)\n",
    "\n",
    "X=df.drop(columns='dengue',axis=1).values\n",
    "y=df['dengue'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1,random_state=42)\n",
    "\n",
    "#torchテンソルに変換\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_4(nn.Module):\n",
    "    def __init__(self, input_dim,hidden_units,dropout1,dropout2,dropout3,dropout4):\n",
    "        super(DNN_4, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,hidden_units)\n",
    "        self.layer2 = nn.Linear(hidden_units,hidden_units)\n",
    "        self.layer3 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.layer4 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.output_layer = nn.Linear(hidden_units, 1)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        self.dropout3 = nn.Dropout(dropout3)\n",
    "        self.dropout4 = nn.Dropout(dropout4)\n",
    "\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_units)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_units)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_units)\n",
    "        self.bn4 = nn.BatchNorm1d(hidden_units)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.relu(self.bn3(self.layer3(x)))\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = torch.relu(self.bn4(self.layer4(x)))\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = torch.sigmoid(self.output_layer(x)) \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optunaの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    hidden_units = trial.suggest_int(\"hidden_units\", 4, 512, step=4)\n",
    "    dropout1 = trial.suggest_float(\"dropout1\", 0.1, 0.5, step=0.05)\n",
    "    dropout2 = trial.suggest_float(\"dropout2\", 0.1, 0.5, step=0.05)\n",
    "    dropout3 = trial.suggest_float(\"dropout3\", 0.1, 0.5, step=0.05)\n",
    "    dropout4 = trial.suggest_float(\"dropout4\", 0.1, 0.5, step=0.05)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
    "    weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
    "    \n",
    "\n",
    "    model = DNN_4(input_dim=X_train_tensor.shape[1], hidden_units=hidden_units, dropout1=dropout1,dropout2=dropout2,dropout3=dropout3,dropout4=dropout4).to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adagrad(model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    val_true, val_pred, val_prob = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            val_outputs = model(X_val).squeeze()\n",
    "            predictions = (val_outputs >= 0.5).float()\n",
    "            val_true.extend(y_val.cpu().numpy())\n",
    "            val_pred.extend(predictions.cpu().numpy())\n",
    "            val_prob.extend(val_outputs.cpu().numpy())\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(val_true, val_pred)\n",
    "    precision = precision_score(val_true, val_pred)\n",
    "    recall = recall_score(val_true, val_pred)\n",
    "    f1 = f1_score(val_true, val_pred)\n",
    "    mcc = matthews_corrcoef(val_true, val_pred)\n",
    "    specificity = recall_score(val_true, val_pred, pos_label=0)\n",
    "\n",
    "    # ログ\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用可能なGPUの数: 2\n",
      "GPU 0: NVIDIA GeForce GTX 1080 Ti\n",
      "  メモリ使用状況: 0.00 MB / 11169.31 MB\n",
      "  CUDA対応バージョン: 6.1\n",
      "GPU 1: NVIDIA GeForce GTX 1080 Ti\n",
      "  メモリ使用状況: 0.00 MB / 11172.19 MB\n",
      "  CUDA対応バージョン: 6.1\n"
     ]
    }
   ],
   "source": [
    "# 使用可能なGPUの数を取得\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "if num_gpus == 0:\n",
    "    print(\"使用可能なGPUはありません。\")\n",
    "else:\n",
    "    print(f\"使用可能なGPUの数: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  メモリ使用状況: {torch.cuda.memory_allocated(i) / 1024**2:.2f} MB / {torch.cuda.get_device_properties(i).total_memory / 1024**2:.2f} MB\")\n",
    "        print(f\"  CUDA対応バージョン: {torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 15:59:22,399] A new study created in memory with name: no-name-5dd75c54-2e89-4284-85cd-a861cc064775\n",
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:00:10,517] Trial 0 finished with value: 0.5977011494252874 and parameters: {'hidden_units': 236, 'dropout1': 0.15000000000000002, 'dropout2': 0.15000000000000002, 'dropout3': 0.4, 'dropout4': 0.30000000000000004, 'learning_rate': 0.016469018462465866, 'weight_decay': 0.010166542577051664}. Best is trial 0 with value: 0.5977011494252874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.11%\n",
      "Precision: 0.4685\n",
      "Recall: 0.8254\n",
      "F1 Score: 0.5977\n",
      "Matthews Correlation Coefficient: 0.2994\n",
      "Specificity: 0.4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:00:58,540] Trial 1 finished with value: 0.4765625 and parameters: {'hidden_units': 316, 'dropout1': 0.35, 'dropout2': 0.25, 'dropout3': 0.35, 'dropout4': 0.5, 'learning_rate': 0.011982097791603863, 'weight_decay': 0.0011007806086053445}. Best is trial 0 with value: 0.5977011494252874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.82%\n",
      "Precision: 0.4692\n",
      "Recall: 0.4841\n",
      "F1 Score: 0.4766\n",
      "Matthews Correlation Coefficient: 0.1763\n",
      "Specificity: 0.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:01:47,168] Trial 2 finished with value: 0.6 and parameters: {'hidden_units': 280, 'dropout1': 0.2, 'dropout2': 0.25, 'dropout3': 0.25, 'dropout4': 0.1, 'learning_rate': 2.2859896494553925e-05, 'weight_decay': 0.019396756478257157}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.25%\n",
      "Precision: 0.4766\n",
      "Recall: 0.8095\n",
      "F1 Score: 0.6000\n",
      "Matthews Correlation Coefficient: 0.3066\n",
      "Specificity: 0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:02:34,241] Trial 3 finished with value: 0.09523809523809523 and parameters: {'hidden_units': 432, 'dropout1': 0.45000000000000007, 'dropout2': 0.5, 'dropout3': 0.4, 'dropout4': 0.45000000000000007, 'learning_rate': 1.5524060918569077e-05, 'weight_decay': 0.0040410960919102}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.11%\n",
      "Precision: 0.3333\n",
      "Recall: 0.0556\n",
      "F1 Score: 0.0952\n",
      "Matthews Correlation Coefficient: -0.0135\n",
      "Specificity: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:03:22,739] Trial 4 finished with value: 0.4674329501915709 and parameters: {'hidden_units': 64, 'dropout1': 0.15000000000000002, 'dropout2': 0.4, 'dropout3': 0.1, 'dropout4': 0.30000000000000004, 'learning_rate': 0.027286994900155976, 'weight_decay': 1.4948015881397066e-05}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.40%\n",
      "Precision: 0.4519\n",
      "Recall: 0.4841\n",
      "F1 Score: 0.4674\n",
      "Matthews Correlation Coefficient: 0.1531\n",
      "Specificity: 0.6711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:04:11,260] Trial 5 finished with value: 0.5473684210526316 and parameters: {'hidden_units': 160, 'dropout1': 0.30000000000000004, 'dropout2': 0.45000000000000007, 'dropout3': 0.35, 'dropout4': 0.4, 'learning_rate': 2.8417575064039566e-05, 'weight_decay': 1.3779721160569217e-05}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.25%\n",
      "Precision: 0.4906\n",
      "Recall: 0.6190\n",
      "F1 Score: 0.5474\n",
      "Matthews Correlation Coefficient: 0.2496\n",
      "Specificity: 0.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:04:59,091] Trial 6 finished with value: 0.5806451612903226 and parameters: {'hidden_units': 504, 'dropout1': 0.25, 'dropout2': 0.35, 'dropout3': 0.25, 'dropout4': 0.25, 'learning_rate': 0.00029184292770589003, 'weight_decay': 0.0018349082309517865}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.96%\n",
      "Precision: 0.4891\n",
      "Recall: 0.7143\n",
      "F1 Score: 0.5806\n",
      "Matthews Correlation Coefficient: 0.2848\n",
      "Specificity: 0.5822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:05:47,820] Trial 7 finished with value: 0.5534591194968553 and parameters: {'hidden_units': 264, 'dropout1': 0.1, 'dropout2': 0.5, 'dropout3': 0.30000000000000004, 'dropout4': 0.35, 'learning_rate': 6.338131703170817e-05, 'weight_decay': 0.0006422350807358796}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.54%\n",
      "Precision: 0.4583\n",
      "Recall: 0.6984\n",
      "F1 Score: 0.5535\n",
      "Matthews Correlation Coefficient: 0.2276\n",
      "Specificity: 0.5378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:06:34,444] Trial 8 finished with value: 0.3380281690140845 and parameters: {'hidden_units': 84, 'dropout1': 0.1, 'dropout2': 0.15000000000000002, 'dropout3': 0.25, 'dropout4': 0.4, 'learning_rate': 6.012662424168033e-05, 'weight_decay': 1.273490144542099e-05}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.83%\n",
      "Precision: 0.4138\n",
      "Recall: 0.2857\n",
      "F1 Score: 0.3380\n",
      "Matthews Correlation Coefficient: 0.0656\n",
      "Specificity: 0.7733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:07:21,644] Trial 9 finished with value: 0.3983050847457627 and parameters: {'hidden_units': 232, 'dropout1': 0.25, 'dropout2': 0.45000000000000007, 'dropout3': 0.4, 'dropout4': 0.5, 'learning_rate': 0.001641171770180525, 'weight_decay': 0.1399721885550067}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.54%\n",
      "Precision: 0.4273\n",
      "Recall: 0.3730\n",
      "F1 Score: 0.3983\n",
      "Matthews Correlation Coefficient: 0.0962\n",
      "Specificity: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:08:09,295] Trial 10 finished with value: 0.46923076923076923 and parameters: {'hidden_units': 372, 'dropout1': 0.5, 'dropout2': 0.25, 'dropout3': 0.5, 'dropout4': 0.1, 'learning_rate': 0.0008003280243950568, 'weight_decay': 0.441371916657878}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.68%\n",
      "Precision: 0.4552\n",
      "Recall: 0.4841\n",
      "F1 Score: 0.4692\n",
      "Matthews Correlation Coefficient: 0.1577\n",
      "Specificity: 0.6756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:08:59,604] Trial 11 finished with value: 0.48412698412698413 and parameters: {'hidden_units': 200, 'dropout1': 0.2, 'dropout2': 0.1, 'dropout3': 0.15000000000000002, 'dropout4': 0.15000000000000002, 'learning_rate': 0.004754944948661651, 'weight_decay': 0.02514839594143094}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.96%\n",
      "Precision: 0.4841\n",
      "Recall: 0.4841\n",
      "F1 Score: 0.4841\n",
      "Matthews Correlation Coefficient: 0.1952\n",
      "Specificity: 0.7111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 16:09:49,193] Trial 12 finished with value: 0.0 and parameters: {'hidden_units': 316, 'dropout1': 0.2, 'dropout2': 0.2, 'dropout3': 0.5, 'dropout4': 0.2, 'learning_rate': 0.02462054825966804, 'weight_decay': 0.020174525549731946}. Best is trial 2 with value: 0.6.\n",
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 16:10:36,608] Trial 13 finished with value: 0.5017921146953405 and parameters: {'hidden_units': 128, 'dropout1': 0.15000000000000002, 'dropout2': 0.1, 'dropout3': 0.2, 'dropout4': 0.25, 'learning_rate': 0.00023329639914241738, 'weight_decay': 0.017441649617359344}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.40%\n",
      "Precision: 0.4575\n",
      "Recall: 0.5556\n",
      "F1 Score: 0.5018\n",
      "Matthews Correlation Coefficient: 0.1806\n",
      "Specificity: 0.6311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:11:24,237] Trial 14 finished with value: 0.39090909090909093 and parameters: {'hidden_units': 316, 'dropout1': 0.4, 'dropout2': 0.30000000000000004, 'dropout3': 0.45000000000000007, 'dropout4': 0.1, 'learning_rate': 0.0913104625261514, 'weight_decay': 0.00029842077120223367}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.82%\n",
      "Precision: 0.4574\n",
      "Recall: 0.3413\n",
      "F1 Score: 0.3909\n",
      "Matthews Correlation Coefficient: 0.1241\n",
      "Specificity: 0.7733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:12:14,121] Trial 15 finished with value: 0.44813278008298757 and parameters: {'hidden_units': 396, 'dropout1': 0.2, 'dropout2': 0.2, 'dropout3': 0.30000000000000004, 'dropout4': 0.30000000000000004, 'learning_rate': 0.003004169418239428, 'weight_decay': 0.07103271107222862}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.11%\n",
      "Precision: 0.4696\n",
      "Recall: 0.4286\n",
      "F1 Score: 0.4481\n",
      "Matthews Correlation Coefficient: 0.1609\n",
      "Specificity: 0.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:13:00,660] Trial 16 finished with value: 0.5602605863192183 and parameters: {'hidden_units': 264, 'dropout1': 0.30000000000000004, 'dropout2': 0.2, 'dropout3': 0.2, 'dropout4': 0.2, 'learning_rate': 0.00029979849798559584, 'weight_decay': 0.005989450501107353}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.54%\n",
      "Precision: 0.4751\n",
      "Recall: 0.6825\n",
      "F1 Score: 0.5603\n",
      "Matthews Correlation Coefficient: 0.2499\n",
      "Specificity: 0.5778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:13:46,734] Trial 17 finished with value: 0.2857142857142857 and parameters: {'hidden_units': 16, 'dropout1': 0.15000000000000002, 'dropout2': 0.30000000000000004, 'dropout3': 0.4, 'dropout4': 0.35, 'learning_rate': 0.0911441290171284, 'weight_decay': 0.00014089581490659407}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.96%\n",
      "Precision: 0.4643\n",
      "Recall: 0.2063\n",
      "F1 Score: 0.2857\n",
      "Matthews Correlation Coefficient: 0.0957\n",
      "Specificity: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 16:14:35,302] Trial 18 finished with value: 0.0 and parameters: {'hidden_units': 188, 'dropout1': 0.25, 'dropout2': 0.15000000000000002, 'dropout3': 0.35, 'dropout4': 0.2, 'learning_rate': 0.007638705974163941, 'weight_decay': 0.29268631137961115}. Best is trial 2 with value: 0.6.\n",
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 16:15:22,513] Trial 19 finished with value: 0.478494623655914 and parameters: {'hidden_units': 132, 'dropout1': 0.1, 'dropout2': 0.25, 'dropout3': 0.25, 'dropout4': 0.15000000000000002, 'learning_rate': 1.0408039109721347e-05, 'weight_decay': 0.7905350767566375}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.73%\n",
      "Precision: 0.3618\n",
      "Recall: 0.7063\n",
      "F1 Score: 0.4785\n",
      "Matthews Correlation Coefficient: 0.0090\n",
      "Specificity: 0.3022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:16:05,042] Trial 20 finished with value: 0.4927536231884058 and parameters: {'hidden_units': 352, 'dropout1': 0.35, 'dropout2': 0.15000000000000002, 'dropout3': 0.45000000000000007, 'dropout4': 0.25, 'learning_rate': 0.0008246173334237139, 'weight_decay': 0.057477155385167684}. Best is trial 2 with value: 0.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.11%\n",
      "Precision: 0.4533\n",
      "Recall: 0.5397\n",
      "F1 Score: 0.4928\n",
      "Matthews Correlation Coefficient: 0.1699\n",
      "Specificity: 0.6356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:16:48,374] Trial 21 finished with value: 0.6128133704735376 and parameters: {'hidden_units': 480, 'dropout1': 0.25, 'dropout2': 0.35, 'dropout3': 0.25, 'dropout4': 0.25, 'learning_rate': 0.00018304864880433922, 'weight_decay': 0.002048976083704054}. Best is trial 21 with value: 0.6128133704735376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.40%\n",
      "Precision: 0.4721\n",
      "Recall: 0.8730\n",
      "F1 Score: 0.6128\n",
      "Matthews Correlation Coefficient: 0.3314\n",
      "Specificity: 0.4533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n",
      "[I 2024-11-28 16:17:31,863] Trial 22 finished with value: 0.5847953216374269 and parameters: {'hidden_units': 512, 'dropout1': 0.2, 'dropout2': 0.35, 'dropout3': 0.2, 'dropout4': 0.35, 'learning_rate': 0.00011831246533359128, 'weight_decay': 0.008029422107829354}. Best is trial 21 with value: 0.6128133704735376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.54%\n",
      "Precision: 0.4630\n",
      "Recall: 0.7937\n",
      "F1 Score: 0.5848\n",
      "Matthews Correlation Coefficient: 0.2742\n",
      "Specificity: 0.4844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97774/1509177502.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "/tmp/ipykernel_97774/1509177502.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\",1e-5,1)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")  \n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "\n",
    "print(\"Best Parameters: \", study.best_params)\n",
    "print(\"Best Validation F1: \", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=study.best_params\n",
    "model = DNN_4(input_dim=X_train_tensor.shape[1],\n",
    "              hidden_units=best_params[\"hidden_units\"],\n",
    "              dropout1=best_params[\"dropout1\"],\n",
    "              dropout2=best_params[\"dropout2\"],\n",
    "              dropout3=best_params[\"dropout3\"],\n",
    "              dropout4=best_params[\"dropout4\"])\n",
    "# 最適化と訓練を実行\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_params[\"learning_rate\"],weight_decay=best_params[\"weight_decay\"])\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs=100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_val_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    if val_loader is not None:\n",
    "        model.eval()  \n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                val_outputs = model(X_val).squeeze()\n",
    "                val_loss = criterion(val_outputs, y_val)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        model.train()  \n",
    "\n",
    "    if val_loader is not None:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "if val_losses:\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for DNN1')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "    # 予測と確率\n",
    "    test_outputs = model(X_test_tensor).squeeze()\n",
    "    predictions = (test_outputs >= 0.5).float()\n",
    "    y_true = y_test_tensor.cpu().numpy()\n",
    "    y_pred = predictions.cpu().numpy()\n",
    "    y_prob = test_outputs.cpu().numpy()\n",
    "\n",
    "# 評価指標\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)  \n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "\n",
    "    # 混同行列（割合表示）\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2%\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix (Normalized)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ROC曲線とAUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--') \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Model ')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # Precision-Recall曲線\n",
    "    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "    plt.plot(recall_curve, precision_curve, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve ')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルと構造を保存\n",
    "torch.save(model, '../../saved_model/DNN_4.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
