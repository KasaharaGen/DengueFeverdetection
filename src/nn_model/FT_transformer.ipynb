{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc,matthews_corrcoef, precision_recall_curve,roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ読み取り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../data/learning_data.csv',index_col=0)\n",
    "\n",
    "X=df.drop(columns='dengue',axis=1).values\n",
    "y=df['dengue'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1,random_state=42)\n",
    "\n",
    "#torchテンソルに変換\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_layers, d_model, dropout):\n",
    "        super(FTTransformer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # 入力を特徴トークンとして埋め込む\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Transformerエンコーダ層\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads, dropout=dropout),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # 出力層\n",
    "        self.fc = nn.Linear(d_model, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 入力を埋め込み\n",
    "        # [batch_size, input_dim] -> [batch_size, seq_len=1, d_model]\n",
    "        x = self.embedding(x).unsqueeze(1)\n",
    "        \n",
    "        # 次元を変更 [batch_size, seq_len, d_model] -> [seq_len, batch_size, d_model]\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        # Transformerエンコーダに通す\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # 最後のトークンを取得して分類\n",
    "        # [seq_len, batch_size, d_model] -> [batch_size, d_model]\n",
    "        x = x.mean(dim=0)  # 平均を取る\n",
    "        x = self.fc(x)  # 出力層\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optunaの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的関数の定義\n",
    "def objective(trial):\n",
    "    # ハイパーパラメータのサンプリング\n",
    "    num_heads = trial.suggest_categorical('num_heads', [2, 4, 8])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    d_model = trial.suggest_categorical('d_model', [32, 64, 128])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5,step=0.05)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "\n",
    "    model = FTTransformer(input_dim=X_train.shape[1], \n",
    "                           num_heads=num_heads, \n",
    "                           num_layers=num_layers, \n",
    "                           d_model=d_model, \n",
    "                           dropout=dropout)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    num_epochs=100\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs,y_batch )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    val_true, val_pred, val_prob = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            val_outputs = model(X_val).squeeze()\n",
    "            predictions = (val_outputs >= 0.5).float()\n",
    "            val_true.extend(y_val.cpu().numpy())\n",
    "            val_pred.extend(predictions.cpu().numpy())\n",
    "            val_prob.extend(val_outputs.cpu().numpy())\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(val_true, val_pred)\n",
    "    precision = precision_score(val_true, val_pred)\n",
    "    recall = recall_score(val_true, val_pred)\n",
    "    f1 = f1_score(val_true, val_pred)\n",
    "    mcc = matthews_corrcoef(val_true, val_pred)\n",
    "    specificity = recall_score(val_true, val_pred, pos_label=0)\n",
    "\n",
    "    # ログ\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用可能なGPUの数: 2\n",
      "GPU 0: NVIDIA GeForce GTX 1080 Ti\n",
      "  メモリ使用状況: 0.00 MB / 11169.31 MB\n",
      "  CUDA対応バージョン: 6.1\n",
      "GPU 1: NVIDIA GeForce GTX 1080 Ti\n",
      "  メモリ使用状況: 0.00 MB / 11172.19 MB\n",
      "  CUDA対応バージョン: 6.1\n"
     ]
    }
   ],
   "source": [
    "# 使用可能なGPUの数を取得\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "if num_gpus == 0:\n",
    "    print(\"使用可能なGPUはありません。\")\n",
    "else:\n",
    "    print(f\"使用可能なGPUの数: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  メモリ使用状況: {torch.cuda.memory_allocated(i) / 1024**2:.2f} MB / {torch.cuda.get_device_properties(i).total_memory / 1024**2:.2f} MB\")\n",
    "        print(f\"  CUDA対応バージョン: {torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 19:02:52,151] A new study created in memory with name: no-name-02e7e6ce-7d94-4b2d-bfa7-02c2369963cb\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:03:57,906] Trial 0 finished with value: 0.5337620578778135 and parameters: {'num_heads': 8, 'num_layers': 1, 'd_model': 64, 'dropout': 0.15000000000000002, 'learning_rate': 0.016282354143651326}. Best is trial 0 with value: 0.5337620578778135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.69%\n",
      "Precision: 0.4486\n",
      "Recall: 0.6587\n",
      "F1 Score: 0.5338\n",
      "Matthews Correlation Coefficient: 0.1973\n",
      "Specificity: 0.5467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:05:52,074] Trial 1 finished with value: 0.6021505376344086 and parameters: {'num_heads': 2, 'num_layers': 3, 'd_model': 32, 'dropout': 0.4, 'learning_rate': 0.0007603256195457132}. Best is trial 1 with value: 0.6021505376344086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.83%\n",
      "Precision: 0.4553\n",
      "Recall: 0.8889\n",
      "F1 Score: 0.6022\n",
      "Matthews Correlation Coefficient: 0.3073\n",
      "Specificity: 0.4044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:08:40,318] Trial 2 finished with value: 0.5283018867924528 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 64, 'dropout': 0.25, 'learning_rate': 0.0878177881338969}. Best is trial 1 with value: 0.6021505376344086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 35.90%\n",
      "Precision: 0.3590\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.5283\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 19:11:01,645] Trial 3 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 64, 'dropout': 0.35, 'learning_rate': 0.03655644203928863}. Best is trial 1 with value: 0.6021505376344086.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 19:13:22,822] Trial 4 finished with value: 0.4322033898305085 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 128, 'dropout': 0.45000000000000007, 'learning_rate': 4.244410828373392e-05}. Best is trial 1 with value: 0.6021505376344086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.82%\n",
      "Precision: 0.4636\n",
      "Recall: 0.4048\n",
      "F1 Score: 0.4322\n",
      "Matthews Correlation Coefficient: 0.1474\n",
      "Specificity: 0.7378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:14:53,241] Trial 5 finished with value: 0.45714285714285713 and parameters: {'num_heads': 2, 'num_layers': 2, 'd_model': 64, 'dropout': 0.30000000000000004, 'learning_rate': 6.794608913770452e-05}. Best is trial 1 with value: 0.6021505376344086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.11%\n",
      "Precision: 0.4706\n",
      "Recall: 0.4444\n",
      "F1 Score: 0.4571\n",
      "Matthews Correlation Coefficient: 0.1666\n",
      "Specificity: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:16:46,604] Trial 6 finished with value: 0.6073298429319371 and parameters: {'num_heads': 4, 'num_layers': 3, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0023505018423643415}. Best is trial 6 with value: 0.6073298429319371.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.26%\n",
      "Precision: 0.4531\n",
      "Recall: 0.9206\n",
      "F1 Score: 0.6073\n",
      "Matthews Correlation Coefficient: 0.3222\n",
      "Specificity: 0.3778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:17:44,169] Trial 7 finished with value: 0.5196850393700787 and parameters: {'num_heads': 8, 'num_layers': 1, 'd_model': 128, 'dropout': 0.1, 'learning_rate': 0.000184437963402636}. Best is trial 6 with value: 0.6073298429319371.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.24%\n",
      "Precision: 0.5156\n",
      "Recall: 0.5238\n",
      "F1 Score: 0.5197\n",
      "Matthews Correlation Coefficient: 0.2474\n",
      "Specificity: 0.7244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 19:20:05,877] Trial 8 finished with value: 0.0 and parameters: {'num_heads': 2, 'num_layers': 4, 'd_model': 128, 'dropout': 0.1, 'learning_rate': 0.0013767388907581224}. Best is trial 6 with value: 0.6073298429319371.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 19:21:36,322] Trial 9 finished with value: 0.0 and parameters: {'num_heads': 8, 'num_layers': 2, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.05490523904454784}. Best is trial 6 with value: 0.6073298429319371.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 19:23:31,808] Trial 10 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 3, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.004063151390332446}. Best is trial 6 with value: 0.6073298429319371.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 19:25:29,239] Trial 11 finished with value: 0.5977653631284916 and parameters: {'num_heads': 2, 'num_layers': 3, 'd_model': 32, 'dropout': 0.4, 'learning_rate': 0.00043487155742115695}. Best is trial 6 with value: 0.6073298429319371.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.97%\n",
      "Precision: 0.4612\n",
      "Recall: 0.8492\n",
      "F1 Score: 0.5978\n",
      "Matthews Correlation Coefficient: 0.2976\n",
      "Specificity: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 19:26:58,766] Trial 12 finished with value: 0.0 and parameters: {'num_heads': 2, 'num_layers': 2, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00469846322094979}. Best is trial 6 with value: 0.6073298429319371.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 19:28:55,356] Trial 13 finished with value: 0.5 and parameters: {'num_heads': 4, 'num_layers': 3, 'd_model': 32, 'dropout': 0.35, 'learning_rate': 1.133811053666828e-05}. Best is trial 6 with value: 0.6073298429319371.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.11%\n",
      "Precision: 0.4545\n",
      "Recall: 0.5556\n",
      "F1 Score: 0.5000\n",
      "Matthews Correlation Coefficient: 0.1762\n",
      "Specificity: 0.6267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 19:31:41,923] Trial 14 finished with value: 0.0 and parameters: {'num_heads': 2, 'num_layers': 5, 'd_model': 32, 'dropout': 0.4, 'learning_rate': 0.0012203684448144794}. Best is trial 6 with value: 0.6073298429319371.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 19:33:12,647] Trial 15 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 2, 'd_model': 32, 'dropout': 0.2, 'learning_rate': 0.005206856938799152}. Best is trial 6 with value: 0.6073298429319371.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 19:35:34,856] Trial 16 finished with value: 0.6237113402061856 and parameters: {'num_heads': 2, 'num_layers': 4, 'd_model': 32, 'dropout': 0.4, 'learning_rate': 0.0003702420627410823}. Best is trial 16 with value: 0.6237113402061856.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.40%\n",
      "Precision: 0.4618\n",
      "Recall: 0.9603\n",
      "F1 Score: 0.6237\n",
      "Matthews Correlation Coefficient: 0.3679\n",
      "Specificity: 0.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:37:56,172] Trial 17 finished with value: 0.5477707006369427 and parameters: {'num_heads': 2, 'num_layers': 4, 'd_model': 32, 'dropout': 0.30000000000000004, 'learning_rate': 0.0001510016587105567}. Best is trial 16 with value: 0.6237113402061856.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.54%\n",
      "Precision: 0.4574\n",
      "Recall: 0.6825\n",
      "F1 Score: 0.5478\n",
      "Matthews Correlation Coefficient: 0.2205\n",
      "Specificity: 0.5467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 19:40:42,841] Trial 18 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0024632934200725116}. Best is trial 16 with value: 0.6237113402061856.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 19:43:04,155] Trial 19 finished with value: 0.0 and parameters: {'num_heads': 8, 'num_layers': 4, 'd_model': 128, 'dropout': 0.35, 'learning_rate': 0.01361821315347561}. Best is trial 16 with value: 0.6237113402061856.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 19:45:27,513] Trial 20 finished with value: 0.6212121212121212 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.0004103773129754718}. Best is trial 16 with value: 0.6237113402061856.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.26%\n",
      "Precision: 0.4556\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.6212\n",
      "Matthews Correlation Coefficient: 0.3676\n",
      "Specificity: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:47:49,129] Trial 21 finished with value: 0.6259541984732825 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.0003814910190920585}. Best is trial 21 with value: 0.6259541984732825.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.12%\n",
      "Precision: 0.4607\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.6260\n",
      "Matthews Correlation Coefficient: 0.3780\n",
      "Specificity: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:50:11,082] Trial 22 finished with value: 0.628140703517588 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.000385109830438782}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.83%\n",
      "Precision: 0.4596\n",
      "Recall: 0.9921\n",
      "F1 Score: 0.6281\n",
      "Matthews Correlation Coefficient: 0.3891\n",
      "Specificity: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:52:58,091] Trial 23 finished with value: 0.628140703517588 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00020391015744903812}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.83%\n",
      "Precision: 0.4596\n",
      "Recall: 0.9921\n",
      "F1 Score: 0.6281\n",
      "Matthews Correlation Coefficient: 0.3891\n",
      "Specificity: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:55:43,392] Trial 24 finished with value: 0.616580310880829 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 6.0421692624770786e-05}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.83%\n",
      "Precision: 0.4577\n",
      "Recall: 0.9444\n",
      "F1 Score: 0.6166\n",
      "Matthews Correlation Coefficient: 0.3479\n",
      "Specificity: 0.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 19:58:29,577] Trial 25 finished with value: 0.6259541984732825 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00013193812743544738}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.12%\n",
      "Precision: 0.4607\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.6260\n",
      "Matthews Correlation Coefficient: 0.3780\n",
      "Specificity: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:01:13,057] Trial 26 finished with value: 0.624 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 3.6709722845750145e-05}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.83%\n",
      "Precision: 0.4699\n",
      "Recall: 0.9286\n",
      "F1 Score: 0.6240\n",
      "Matthews Correlation Coefficient: 0.3612\n",
      "Specificity: 0.4133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:03:37,854] Trial 27 finished with value: 0.6005361930294906 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 1.7166539949872812e-05}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4534\n",
      "Recall: 0.8889\n",
      "F1 Score: 0.6005\n",
      "Matthews Correlation Coefficient: 0.3035\n",
      "Specificity: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 20:06:27,669] Trial 28 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 128, 'dropout': 0.45000000000000007, 'learning_rate': 0.00023483618008180717}. Best is trial 22 with value: 0.628140703517588.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 20:08:50,532] Trial 29 finished with value: 0.0 and parameters: {'num_heads': 8, 'num_layers': 4, 'd_model': 64, 'dropout': 0.2, 'learning_rate': 0.0007126698619779685}. Best is trial 22 with value: 0.628140703517588.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 20:11:41,493] Trial 30 finished with value: 0.6246851385390428 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 64, 'dropout': 0.4, 'learning_rate': 0.0002735076418144564}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4576\n",
      "Recall: 0.9841\n",
      "F1 Score: 0.6247\n",
      "Matthews Correlation Coefficient: 0.3783\n",
      "Specificity: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:14:28,167] Trial 31 finished with value: 0.6246851385390428 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00011113388194059287}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4576\n",
      "Recall: 0.9841\n",
      "F1 Score: 0.6247\n",
      "Matthews Correlation Coefficient: 0.3783\n",
      "Specificity: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:17:13,873] Trial 32 finished with value: 0.5994397759103641 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.0006989729655520919}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.26%\n",
      "Precision: 0.4632\n",
      "Recall: 0.8492\n",
      "F1 Score: 0.5994\n",
      "Matthews Correlation Coefficient: 0.3015\n",
      "Specificity: 0.4489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:19:57,700] Trial 33 finished with value: 0.6181818181818182 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.00010082113335718151}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.12%\n",
      "Precision: 0.4595\n",
      "Recall: 0.9444\n",
      "F1 Score: 0.6182\n",
      "Matthews Correlation Coefficient: 0.3515\n",
      "Specificity: 0.3778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:22:18,528] Trial 34 finished with value: 0.6253229974160207 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 3.138148807011191e-05}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.69%\n",
      "Precision: 0.4636\n",
      "Recall: 0.9603\n",
      "F1 Score: 0.6253\n",
      "Matthews Correlation Coefficient: 0.3714\n",
      "Specificity: 0.3778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:24:23,816] Trial 35 finished with value: 0.24858757062146894 and parameters: {'num_heads': 4, 'num_layers': 3, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.00011750021768094866}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.11%\n",
      "Precision: 0.4314\n",
      "Recall: 0.1746\n",
      "F1 Score: 0.2486\n",
      "Matthews Correlation Coefficient: 0.0622\n",
      "Specificity: 0.8711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 20:27:48,586] Trial 36 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 64, 'dropout': 0.4, 'learning_rate': 0.0006467977649708419}. Best is trial 22 with value: 0.628140703517588.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 20:31:14,303] Trial 37 finished with value: 0.38461538461538464 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.25, 'learning_rate': 8.439904253991151e-05}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.53%\n",
      "Precision: 0.4878\n",
      "Recall: 0.3175\n",
      "F1 Score: 0.3846\n",
      "Matthews Correlation Coefficient: 0.1483\n",
      "Specificity: 0.8133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:34:53,836] Trial 38 finished with value: 0.616580310880829 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.35, 'learning_rate': 0.0002163529050807547}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.83%\n",
      "Precision: 0.4577\n",
      "Recall: 0.9444\n",
      "F1 Score: 0.6166\n",
      "Matthews Correlation Coefficient: 0.3479\n",
      "Specificity: 0.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 20:38:11,993] Trial 39 finished with value: 0.0 and parameters: {'num_heads': 8, 'num_layers': 4, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 0.001553278497974592}. Best is trial 22 with value: 0.628140703517588.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 20:41:28,382] Trial 40 finished with value: 0.5223367697594502 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 64, 'dropout': 0.45000000000000007, 'learning_rate': 2.27781873532099e-05}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.40%\n",
      "Precision: 0.4606\n",
      "Recall: 0.6032\n",
      "F1 Score: 0.5223\n",
      "Matthews Correlation Coefficient: 0.1995\n",
      "Specificity: 0.6044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:44:40,198] Trial 41 finished with value: 0.6272493573264781 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 4.474112480238049e-05}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.69%\n",
      "Precision: 0.4639\n",
      "Recall: 0.9683\n",
      "F1 Score: 0.6272\n",
      "Matthews Correlation Coefficient: 0.3781\n",
      "Specificity: 0.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:47:23,277] Trial 42 finished with value: 0.5730659025787965 and parameters: {'num_heads': 4, 'num_layers': 3, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 6.264513735582374e-05}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4484\n",
      "Recall: 0.7937\n",
      "F1 Score: 0.5731\n",
      "Matthews Correlation Coefficient: 0.2461\n",
      "Specificity: 0.4533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:50:00,412] Trial 43 finished with value: 0.5431309904153354 and parameters: {'num_heads': 4, 'num_layers': 3, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.00015860730835494684}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.26%\n",
      "Precision: 0.4545\n",
      "Recall: 0.6746\n",
      "F1 Score: 0.5431\n",
      "Matthews Correlation Coefficient: 0.2127\n",
      "Specificity: 0.5467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:53:14,474] Trial 44 finished with value: 0.5548780487804879 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 5.111501119999971e-05}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.40%\n",
      "Precision: 0.4505\n",
      "Recall: 0.7222\n",
      "F1 Score: 0.5549\n",
      "Matthews Correlation Coefficient: 0.2221\n",
      "Specificity: 0.5067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:54:34,579] Trial 45 finished with value: 0.5037037037037037 and parameters: {'num_heads': 4, 'num_layers': 1, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00035596273358270893}. Best is trial 22 with value: 0.628140703517588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.82%\n",
      "Precision: 0.4722\n",
      "Recall: 0.5397\n",
      "F1 Score: 0.5037\n",
      "Matthews Correlation Coefficient: 0.1969\n",
      "Specificity: 0.6622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 20:58:18,429] Trial 46 finished with value: 0.629156010230179 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0002694475272998857}. Best is trial 46 with value: 0.629156010230179.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.69%\n",
      "Precision: 0.4642\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.6292\n",
      "Matthews Correlation Coefficient: 0.3849\n",
      "Specificity: 0.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 21:01:37,042] Trial 47 finished with value: 0.0 and parameters: {'num_heads': 8, 'num_layers': 4, 'd_model': 128, 'dropout': 0.45000000000000007, 'learning_rate': 0.0005470400883643458}. Best is trial 46 with value: 0.629156010230179.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 21:04:16,460] Trial 48 finished with value: 0.6098901098901099 and parameters: {'num_heads': 4, 'num_layers': 3, 'd_model': 32, 'dropout': 0.4, 'learning_rate': 0.0002729692083199856}. Best is trial 46 with value: 0.629156010230179.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.54%\n",
      "Precision: 0.4664\n",
      "Recall: 0.8810\n",
      "F1 Score: 0.6099\n",
      "Matthews Correlation Coefficient: 0.3250\n",
      "Specificity: 0.4356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 21:08:02,174] Trial 49 finished with value: 0.6121372031662269 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0011085643634859551}. Best is trial 46 with value: 0.629156010230179.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.12%\n",
      "Precision: 0.4585\n",
      "Recall: 0.9206\n",
      "F1 Score: 0.6121\n",
      "Matthews Correlation Coefficient: 0.3334\n",
      "Specificity: 0.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 21:11:19,828] Trial 50 finished with value: 0.0 and parameters: {'num_heads': 2, 'num_layers': 4, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0020328381489570584}. Best is trial 46 with value: 0.629156010230179.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 21:15:09,243] Trial 51 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00016056464553078134}. Best is trial 46 with value: 0.629156010230179.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 21:18:53,534] Trial 52 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.0002969431596659384}. Best is trial 46 with value: 0.629156010230179.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 21:22:39,669] Trial 53 finished with value: 0.6243654822335025 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 8.069518898860847e-05}. Best is trial 46 with value: 0.629156010230179.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.83%\n",
      "Precision: 0.4590\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.6244\n",
      "Matthews Correlation Coefficient: 0.3745\n",
      "Specificity: 0.3556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 21:26:20,277] Trial 54 finished with value: 0.6294416243654822 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00014611773136497693}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.40%\n",
      "Precision: 0.4627\n",
      "Recall: 0.9841\n",
      "F1 Score: 0.6294\n",
      "Matthews Correlation Coefficient: 0.3885\n",
      "Specificity: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 21:29:38,525] Trial 55 finished with value: 0.6212121212121212 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0005176508960321835}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.26%\n",
      "Precision: 0.4556\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.6212\n",
      "Matthews Correlation Coefficient: 0.3676\n",
      "Specificity: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 21:33:21,912] Trial 56 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.15000000000000002, 'learning_rate': 0.0008506503653817938}. Best is trial 54 with value: 0.6294416243654822.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 21:36:35,501] Trial 57 finished with value: 0.618925831202046 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.4, 'learning_rate': 0.00019658704695881465}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4566\n",
      "Recall: 0.9603\n",
      "F1 Score: 0.6189\n",
      "Matthews Correlation Coefficient: 0.3573\n",
      "Specificity: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 21:40:11,101] Trial 58 finished with value: 0.6194225721784777 and parameters: {'num_heads': 2, 'num_layers': 5, 'd_model': 64, 'dropout': 0.5, 'learning_rate': 4.2736213326823144e-05}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.69%\n",
      "Precision: 0.4627\n",
      "Recall: 0.9365\n",
      "F1 Score: 0.6194\n",
      "Matthews Correlation Coefficient: 0.3526\n",
      "Specificity: 0.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 21:42:56,144] Trial 59 finished with value: 0.56875 and parameters: {'num_heads': 8, 'num_layers': 3, 'd_model': 128, 'dropout': 0.45000000000000007, 'learning_rate': 2.2956326753760725e-05}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.68%\n",
      "Precision: 0.4691\n",
      "Recall: 0.7222\n",
      "F1 Score: 0.5687\n",
      "Matthews Correlation Coefficient: 0.2551\n",
      "Specificity: 0.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 21:44:57,333] Trial 60 finished with value: 0.5571847507331378 and parameters: {'num_heads': 4, 'num_layers': 2, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00043096953024122724}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.98%\n",
      "Precision: 0.4419\n",
      "Recall: 0.7540\n",
      "F1 Score: 0.5572\n",
      "Matthews Correlation Coefficient: 0.2173\n",
      "Specificity: 0.4667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 21:48:37,992] Trial 61 finished with value: 0.6259541984732825 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00010852494421363591}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.12%\n",
      "Precision: 0.4607\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.6260\n",
      "Matthews Correlation Coefficient: 0.3780\n",
      "Specificity: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 21:52:16,506] Trial 62 finished with value: 0.6243654822335025 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00013079625957865493}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.83%\n",
      "Precision: 0.4590\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.6244\n",
      "Matthews Correlation Coefficient: 0.3745\n",
      "Specificity: 0.3556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 21:55:52,121] Trial 63 finished with value: 0.6208651399491094 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00021502802937777696}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4569\n",
      "Recall: 0.9683\n",
      "F1 Score: 0.6209\n",
      "Matthews Correlation Coefficient: 0.3641\n",
      "Specificity: 0.3556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 21:59:24,742] Trial 64 finished with value: 0.6226912928759895 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 1.0742972177725787e-05}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.26%\n",
      "Precision: 0.4664\n",
      "Recall: 0.9365\n",
      "F1 Score: 0.6227\n",
      "Matthews Correlation Coefficient: 0.3598\n",
      "Specificity: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 22:02:37,513] Trial 65 finished with value: 0.6288659793814433 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00034898609624037447}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.97%\n",
      "Precision: 0.4656\n",
      "Recall: 0.9683\n",
      "F1 Score: 0.6289\n",
      "Matthews Correlation Coefficient: 0.3815\n",
      "Specificity: 0.3778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 22:05:54,029] Trial 66 finished with value: 0.6246851385390428 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00035662752088246665}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4576\n",
      "Recall: 0.9841\n",
      "F1 Score: 0.6247\n",
      "Matthews Correlation Coefficient: 0.3783\n",
      "Specificity: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 22:09:06,449] Trial 67 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.30000000000000004, 'learning_rate': 0.0005034750905327589}. Best is trial 54 with value: 0.6294416243654822.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 22:12:19,220] Trial 68 finished with value: 0.6142506142506142 and parameters: {'num_heads': 2, 'num_layers': 4, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0009714541094366088}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.27%\n",
      "Precision: 0.4448\n",
      "Recall: 0.9921\n",
      "F1 Score: 0.6143\n",
      "Matthews Correlation Coefficient: 0.3586\n",
      "Specificity: 0.3067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 22:15:31,538] Trial 69 finished with value: 0.6113989637305699 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.000296295101670698}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.26%\n",
      "Precision: 0.4538\n",
      "Recall: 0.9365\n",
      "F1 Score: 0.6114\n",
      "Matthews Correlation Coefficient: 0.3343\n",
      "Specificity: 0.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 22:18:47,627] Trial 70 finished with value: 0.3482587064676617 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 64, 'dropout': 0.25, 'learning_rate': 9.075169778015119e-05}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.68%\n",
      "Precision: 0.4667\n",
      "Recall: 0.2778\n",
      "F1 Score: 0.3483\n",
      "Matthews Correlation Coefficient: 0.1170\n",
      "Specificity: 0.8222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 22:22:19,718] Trial 71 finished with value: 0.6294416243654822 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00017452383741586486}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.40%\n",
      "Precision: 0.4627\n",
      "Recall: 0.9841\n",
      "F1 Score: 0.6294\n",
      "Matthews Correlation Coefficient: 0.3885\n",
      "Specificity: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 22:26:01,555] Trial 72 finished with value: 0.6215538847117794 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00017717857941687212}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.98%\n",
      "Precision: 0.4542\n",
      "Recall: 0.9841\n",
      "F1 Score: 0.6216\n",
      "Matthews Correlation Coefficient: 0.3714\n",
      "Specificity: 0.3378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 22:29:47,921] Trial 73 finished with value: 0.62 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00022357989288231066}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.70%\n",
      "Precision: 0.4526\n",
      "Recall: 0.9841\n",
      "F1 Score: 0.6200\n",
      "Matthews Correlation Coefficient: 0.3680\n",
      "Specificity: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 22:33:34,925] Trial 74 finished with value: 0.5283018867924528 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.09339575478505686}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 35.90%\n",
      "Precision: 0.3590\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.5283\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 22:36:50,302] Trial 75 finished with value: 0.6208651399491094 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 6.8427801682008e-05}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4569\n",
      "Recall: 0.9683\n",
      "F1 Score: 0.6209\n",
      "Matthews Correlation Coefficient: 0.3641\n",
      "Specificity: 0.3556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 22:39:27,081] Trial 76 finished with value: 0.0 and parameters: {'num_heads': 8, 'num_layers': 3, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 0.01076818031706878}. Best is trial 54 with value: 0.6294416243654822.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 22:43:02,387] Trial 77 finished with value: 0.6265664160401002 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0003479812302209431}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4579\n",
      "Recall: 0.9921\n",
      "F1 Score: 0.6266\n",
      "Matthews Correlation Coefficient: 0.3857\n",
      "Specificity: 0.3422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 22:46:49,594] Trial 78 finished with value: 0.425531914893617 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.4, 'learning_rate': 0.0006213586752194319}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.54%\n",
      "Precision: 0.4587\n",
      "Recall: 0.3968\n",
      "F1 Score: 0.4255\n",
      "Matthews Correlation Coefficient: 0.1395\n",
      "Specificity: 0.7378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 22:50:23,917] Trial 79 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.05334234482522784}. Best is trial 54 with value: 0.6294416243654822.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 22:54:01,576] Trial 80 finished with value: 0.6233766233766234 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.35, 'learning_rate': 0.0001406287513629186}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.69%\n",
      "Precision: 0.4633\n",
      "Recall: 0.9524\n",
      "F1 Score: 0.6234\n",
      "Matthews Correlation Coefficient: 0.3650\n",
      "Specificity: 0.3822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-11-28 22:57:37,689] Trial 81 finished with value: 0.0 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00034171207216110444}. Best is trial 54 with value: 0.6294416243654822.\n",
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.10%\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Matthews Correlation Coefficient: 0.0000\n",
      "Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-28 23:01:15,592] Trial 82 finished with value: 0.6259541984732825 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0004477587769132317}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.12%\n",
      "Precision: 0.4607\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.6260\n",
      "Matthews Correlation Coefficient: 0.3780\n",
      "Specificity: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:04:23,960] Trial 83 finished with value: 0.6272493573264781 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.00027475637238447175}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.69%\n",
      "Precision: 0.4639\n",
      "Recall: 0.9683\n",
      "F1 Score: 0.6272\n",
      "Matthews Correlation Coefficient: 0.3781\n",
      "Specificity: 0.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:08:09,575] Trial 84 finished with value: 0.6224489795918368 and parameters: {'num_heads': 4, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0002755318037901093}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.83%\n",
      "Precision: 0.4586\n",
      "Recall: 0.9683\n",
      "F1 Score: 0.6224\n",
      "Matthews Correlation Coefficient: 0.3676\n",
      "Specificity: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:10:09,412] Trial 85 finished with value: 0.503448275862069 and parameters: {'num_heads': 4, 'num_layers': 2, 'd_model': 32, 'dropout': 0.4, 'learning_rate': 0.0001819247751119411}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.97%\n",
      "Precision: 0.4451\n",
      "Recall: 0.5794\n",
      "F1 Score: 0.5034\n",
      "Matthews Correlation Coefficient: 0.1682\n",
      "Specificity: 0.5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:13:20,032] Trial 86 finished with value: 0.62 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0007483578092959912}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.70%\n",
      "Precision: 0.4526\n",
      "Recall: 0.9841\n",
      "F1 Score: 0.6200\n",
      "Matthews Correlation Coefficient: 0.3680\n",
      "Specificity: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:16:58,962] Trial 87 finished with value: 0.6227848101265823 and parameters: {'num_heads': 2, 'num_layers': 5, 'd_model': 32, 'dropout': 0.45000000000000007, 'learning_rate': 0.0002472811311567939}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4572\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.6228\n",
      "Matthews Correlation Coefficient: 0.3711\n",
      "Specificity: 0.3511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:20:16,378] Trial 88 finished with value: 0.5730994152046783 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 64, 'dropout': 0.4, 'learning_rate': 7.4545321191838e-05}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.40%\n",
      "Precision: 0.4537\n",
      "Recall: 0.7778\n",
      "F1 Score: 0.5731\n",
      "Matthews Correlation Coefficient: 0.2498\n",
      "Specificity: 0.4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:23:33,901] Trial 89 finished with value: 0.6233766233766234 and parameters: {'num_heads': 4, 'num_layers': 4, 'd_model': 32, 'dropout': 0.5, 'learning_rate': 0.00014975614113004433}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.69%\n",
      "Precision: 0.4633\n",
      "Recall: 0.9524\n",
      "F1 Score: 0.6234\n",
      "Matthews Correlation Coefficient: 0.3650\n",
      "Specificity: 0.3822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:27:12,320] Trial 90 finished with value: 0.6282722513089005 and parameters: {'num_heads': 8, 'num_layers': 5, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 5.3134614759440934e-05}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.54%\n",
      "Precision: 0.4688\n",
      "Recall: 0.9524\n",
      "F1 Score: 0.6283\n",
      "Matthews Correlation Coefficient: 0.3757\n",
      "Specificity: 0.3956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:30:54,193] Trial 91 finished with value: 0.5779036827195467 and parameters: {'num_heads': 8, 'num_layers': 5, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 3.432271766166396e-05}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.55%\n",
      "Precision: 0.4493\n",
      "Recall: 0.8095\n",
      "F1 Score: 0.5779\n",
      "Matthews Correlation Coefficient: 0.2549\n",
      "Specificity: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:34:32,243] Trial 92 finished with value: 0.5950413223140496 and parameters: {'num_heads': 8, 'num_layers': 5, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 4.913517142596972e-05}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.12%\n",
      "Precision: 0.4557\n",
      "Recall: 0.8571\n",
      "F1 Score: 0.5950\n",
      "Matthews Correlation Coefficient: 0.2907\n",
      "Specificity: 0.4267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:38:25,157] Trial 93 finished with value: 0.6266318537859008 and parameters: {'num_heads': 8, 'num_layers': 5, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 1.8678866185193544e-05}. Best is trial 54 with value: 0.6294416243654822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.26%\n",
      "Precision: 0.4669\n",
      "Recall: 0.9524\n",
      "F1 Score: 0.6266\n",
      "Matthews Correlation Coefficient: 0.3721\n",
      "Specificity: 0.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:42:05,901] Trial 94 finished with value: 0.6321243523316062 and parameters: {'num_heads': 8, 'num_layers': 5, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 1.4506550279902921e-05}. Best is trial 94 with value: 0.6321243523316062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.54%\n",
      "Precision: 0.4692\n",
      "Recall: 0.9683\n",
      "F1 Score: 0.6321\n",
      "Matthews Correlation Coefficient: 0.3885\n",
      "Specificity: 0.3867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:45:42,762] Trial 95 finished with value: 0.6129032258064516 and parameters: {'num_heads': 8, 'num_layers': 5, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 3.0481431719178153e-05}. Best is trial 94 with value: 0.6321243523316062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.97%\n",
      "Precision: 0.4634\n",
      "Recall: 0.9048\n",
      "F1 Score: 0.6129\n",
      "Matthews Correlation Coefficient: 0.3333\n",
      "Specificity: 0.4133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:49:19,842] Trial 96 finished with value: 0.6174142480211082 and parameters: {'num_heads': 8, 'num_layers': 5, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 1.5841439267589005e-05}. Best is trial 94 with value: 0.6321243523316062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.69%\n",
      "Precision: 0.4625\n",
      "Recall: 0.9286\n",
      "F1 Score: 0.6174\n",
      "Matthews Correlation Coefficient: 0.3466\n",
      "Specificity: 0.3956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:52:32,341] Trial 97 finished with value: 0.5085910652920962 and parameters: {'num_heads': 8, 'num_layers': 4, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 2.678480457299264e-05}. Best is trial 94 with value: 0.6321243523316062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.26%\n",
      "Precision: 0.4485\n",
      "Recall: 0.5873\n",
      "F1 Score: 0.5086\n",
      "Matthews Correlation Coefficient: 0.1757\n",
      "Specificity: 0.5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:56:07,062] Trial 98 finished with value: 0.6304909560723514 and parameters: {'num_heads': 8, 'num_layers': 5, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 1.4500780952912481e-05}. Best is trial 94 with value: 0.6321243523316062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.26%\n",
      "Precision: 0.4674\n",
      "Recall: 0.9683\n",
      "F1 Score: 0.6305\n",
      "Matthews Correlation Coefficient: 0.3850\n",
      "Specificity: 0.3822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187141/2037634495.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[I 2024-11-28 23:59:48,022] Trial 99 finished with value: 0.6230366492146597 and parameters: {'num_heads': 8, 'num_layers': 5, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 1.601823907661446e-05}. Best is trial 94 with value: 0.6321243523316062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.97%\n",
      "Precision: 0.4648\n",
      "Recall: 0.9444\n",
      "F1 Score: 0.6230\n",
      "Matthews Correlation Coefficient: 0.3623\n",
      "Specificity: 0.3911\n",
      "Best Parameters:  {'num_heads': 8, 'num_layers': 5, 'd_model': 128, 'dropout': 0.5, 'learning_rate': 1.4506550279902921e-05}\n",
      "Best Validation F1:  0.6321243523316062\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")  \n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "\n",
    "print(\"Best Parameters: \", study.best_params)\n",
    "print(\"Best Validation F1: \", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonken/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.6739\n",
      "Epoch [1/200], Train Loss: 0.6739, Val Loss: 0.6002\n",
      "Epoch [2/200], Loss: 0.6584\n",
      "Epoch [2/200], Train Loss: 0.6584, Val Loss: 0.5941\n",
      "Epoch [3/200], Loss: 0.6418\n",
      "Epoch [3/200], Train Loss: 0.6418, Val Loss: 0.5950\n",
      "Epoch [4/200], Loss: 0.6327\n",
      "Epoch [4/200], Train Loss: 0.6327, Val Loss: 0.5949\n",
      "Epoch [5/200], Loss: 0.6247\n",
      "Epoch [5/200], Train Loss: 0.6247, Val Loss: 0.5957\n",
      "Epoch [6/200], Loss: 0.6220\n",
      "Epoch [6/200], Train Loss: 0.6220, Val Loss: 0.5967\n",
      "Epoch [7/200], Loss: 0.6146\n",
      "Epoch [7/200], Train Loss: 0.6146, Val Loss: 0.5984\n",
      "Epoch [8/200], Loss: 0.6146\n",
      "Epoch [8/200], Train Loss: 0.6146, Val Loss: 0.5935\n",
      "Epoch [9/200], Loss: 0.6036\n",
      "Epoch [9/200], Train Loss: 0.6036, Val Loss: 0.5892\n",
      "Epoch [10/200], Loss: 0.5963\n",
      "Epoch [10/200], Train Loss: 0.5963, Val Loss: 0.5997\n",
      "Epoch [11/200], Loss: 0.5997\n",
      "Epoch [11/200], Train Loss: 0.5997, Val Loss: 0.5857\n",
      "Epoch [12/200], Loss: 0.5974\n",
      "Epoch [12/200], Train Loss: 0.5974, Val Loss: 0.5954\n",
      "Epoch [13/200], Loss: 0.5925\n",
      "Epoch [13/200], Train Loss: 0.5925, Val Loss: 0.5810\n",
      "Epoch [14/200], Loss: 0.5915\n",
      "Epoch [14/200], Train Loss: 0.5915, Val Loss: 0.5804\n",
      "Epoch [15/200], Loss: 0.5863\n",
      "Epoch [15/200], Train Loss: 0.5863, Val Loss: 0.5811\n",
      "Epoch [16/200], Loss: 0.5854\n",
      "Epoch [16/200], Train Loss: 0.5854, Val Loss: 0.5846\n",
      "Epoch [17/200], Loss: 0.5766\n",
      "Epoch [17/200], Train Loss: 0.5766, Val Loss: 0.5773\n",
      "Epoch [18/200], Loss: 0.5868\n",
      "Epoch [18/200], Train Loss: 0.5868, Val Loss: 0.5838\n",
      "Epoch [19/200], Loss: 0.5817\n",
      "Epoch [19/200], Train Loss: 0.5817, Val Loss: 0.5808\n",
      "Epoch [20/200], Loss: 0.5735\n",
      "Epoch [20/200], Train Loss: 0.5735, Val Loss: 0.5796\n",
      "Epoch [21/200], Loss: 0.5762\n",
      "Epoch [21/200], Train Loss: 0.5762, Val Loss: 0.5768\n",
      "Epoch [22/200], Loss: 0.5753\n",
      "Epoch [22/200], Train Loss: 0.5753, Val Loss: 0.5783\n",
      "Epoch [23/200], Loss: 0.5786\n",
      "Epoch [23/200], Train Loss: 0.5786, Val Loss: 0.5768\n",
      "Epoch [24/200], Loss: 0.5714\n",
      "Epoch [24/200], Train Loss: 0.5714, Val Loss: 0.5715\n",
      "Epoch [25/200], Loss: 0.5700\n",
      "Epoch [25/200], Train Loss: 0.5700, Val Loss: 0.5789\n",
      "Epoch [26/200], Loss: 0.5692\n",
      "Epoch [26/200], Train Loss: 0.5692, Val Loss: 0.5725\n",
      "Epoch [27/200], Loss: 0.5759\n",
      "Epoch [27/200], Train Loss: 0.5759, Val Loss: 0.5712\n",
      "Epoch [28/200], Loss: 0.5718\n",
      "Epoch [28/200], Train Loss: 0.5718, Val Loss: 0.5725\n",
      "Epoch [29/200], Loss: 0.5734\n",
      "Epoch [29/200], Train Loss: 0.5734, Val Loss: 0.5762\n",
      "Epoch [30/200], Loss: 0.5661\n",
      "Epoch [30/200], Train Loss: 0.5661, Val Loss: 0.5713\n",
      "Epoch [31/200], Loss: 0.5703\n",
      "Epoch [31/200], Train Loss: 0.5703, Val Loss: 0.5701\n",
      "Epoch [32/200], Loss: 0.5696\n",
      "Epoch [32/200], Train Loss: 0.5696, Val Loss: 0.5731\n",
      "Epoch [33/200], Loss: 0.5713\n",
      "Epoch [33/200], Train Loss: 0.5713, Val Loss: 0.5718\n",
      "Epoch [34/200], Loss: 0.5651\n",
      "Epoch [34/200], Train Loss: 0.5651, Val Loss: 0.5748\n",
      "Epoch [35/200], Loss: 0.5677\n",
      "Epoch [35/200], Train Loss: 0.5677, Val Loss: 0.5740\n",
      "Epoch [36/200], Loss: 0.5666\n",
      "Epoch [36/200], Train Loss: 0.5666, Val Loss: 0.5741\n",
      "Epoch [37/200], Loss: 0.5652\n",
      "Epoch [37/200], Train Loss: 0.5652, Val Loss: 0.5778\n",
      "Epoch [38/200], Loss: 0.5681\n",
      "Epoch [38/200], Train Loss: 0.5681, Val Loss: 0.5741\n",
      "Epoch [39/200], Loss: 0.5665\n",
      "Epoch [39/200], Train Loss: 0.5665, Val Loss: 0.5749\n",
      "Epoch [40/200], Loss: 0.5655\n",
      "Epoch [40/200], Train Loss: 0.5655, Val Loss: 0.5690\n",
      "Epoch [41/200], Loss: 0.5660\n",
      "Epoch [41/200], Train Loss: 0.5660, Val Loss: 0.5801\n",
      "Epoch [42/200], Loss: 0.5658\n",
      "Epoch [42/200], Train Loss: 0.5658, Val Loss: 0.5738\n",
      "Epoch [43/200], Loss: 0.5592\n",
      "Epoch [43/200], Train Loss: 0.5592, Val Loss: 0.5773\n",
      "Epoch [44/200], Loss: 0.5651\n",
      "Epoch [44/200], Train Loss: 0.5651, Val Loss: 0.5764\n",
      "Epoch [45/200], Loss: 0.5704\n",
      "Epoch [45/200], Train Loss: 0.5704, Val Loss: 0.5756\n",
      "Epoch [46/200], Loss: 0.5667\n",
      "Epoch [46/200], Train Loss: 0.5667, Val Loss: 0.5739\n",
      "Epoch [47/200], Loss: 0.5627\n",
      "Epoch [47/200], Train Loss: 0.5627, Val Loss: 0.5763\n",
      "Epoch [48/200], Loss: 0.5653\n",
      "Epoch [48/200], Train Loss: 0.5653, Val Loss: 0.5726\n",
      "Epoch [49/200], Loss: 0.5653\n",
      "Epoch [49/200], Train Loss: 0.5653, Val Loss: 0.5788\n",
      "Epoch [50/200], Loss: 0.5684\n",
      "Epoch [50/200], Train Loss: 0.5684, Val Loss: 0.5739\n",
      "Epoch [51/200], Loss: 0.5673\n",
      "Epoch [51/200], Train Loss: 0.5673, Val Loss: 0.5768\n",
      "Epoch [52/200], Loss: 0.5639\n",
      "Epoch [52/200], Train Loss: 0.5639, Val Loss: 0.5693\n",
      "Epoch [53/200], Loss: 0.5644\n",
      "Epoch [53/200], Train Loss: 0.5644, Val Loss: 0.5672\n",
      "Epoch [54/200], Loss: 0.5654\n",
      "Epoch [54/200], Train Loss: 0.5654, Val Loss: 0.5716\n",
      "Epoch [55/200], Loss: 0.5666\n",
      "Epoch [55/200], Train Loss: 0.5666, Val Loss: 0.5723\n",
      "Epoch [56/200], Loss: 0.5650\n",
      "Epoch [56/200], Train Loss: 0.5650, Val Loss: 0.5712\n",
      "Epoch [57/200], Loss: 0.5648\n",
      "Epoch [57/200], Train Loss: 0.5648, Val Loss: 0.5778\n",
      "Epoch [58/200], Loss: 0.5612\n",
      "Epoch [58/200], Train Loss: 0.5612, Val Loss: 0.5734\n",
      "Epoch [59/200], Loss: 0.5624\n",
      "Epoch [59/200], Train Loss: 0.5624, Val Loss: 0.5758\n",
      "Epoch [60/200], Loss: 0.5664\n",
      "Epoch [60/200], Train Loss: 0.5664, Val Loss: 0.5739\n",
      "Epoch [61/200], Loss: 0.5630\n",
      "Epoch [61/200], Train Loss: 0.5630, Val Loss: 0.5774\n",
      "Epoch [62/200], Loss: 0.5660\n",
      "Epoch [62/200], Train Loss: 0.5660, Val Loss: 0.5710\n",
      "Epoch [63/200], Loss: 0.5681\n",
      "Epoch [63/200], Train Loss: 0.5681, Val Loss: 0.5708\n",
      "Epoch [64/200], Loss: 0.5642\n",
      "Epoch [64/200], Train Loss: 0.5642, Val Loss: 0.5739\n",
      "Epoch [65/200], Loss: 0.5582\n",
      "Epoch [65/200], Train Loss: 0.5582, Val Loss: 0.5766\n",
      "Epoch [66/200], Loss: 0.5647\n",
      "Epoch [66/200], Train Loss: 0.5647, Val Loss: 0.5748\n",
      "Epoch [67/200], Loss: 0.5621\n",
      "Epoch [67/200], Train Loss: 0.5621, Val Loss: 0.5772\n",
      "Epoch [68/200], Loss: 0.5632\n",
      "Epoch [68/200], Train Loss: 0.5632, Val Loss: 0.5768\n",
      "Epoch [69/200], Loss: 0.5627\n",
      "Epoch [69/200], Train Loss: 0.5627, Val Loss: 0.5765\n",
      "Epoch [70/200], Loss: 0.5636\n",
      "Epoch [70/200], Train Loss: 0.5636, Val Loss: 0.5767\n",
      "Epoch [71/200], Loss: 0.5614\n",
      "Epoch [71/200], Train Loss: 0.5614, Val Loss: 0.5760\n",
      "Epoch [72/200], Loss: 0.5603\n",
      "Epoch [72/200], Train Loss: 0.5603, Val Loss: 0.5728\n",
      "Epoch [73/200], Loss: 0.5649\n",
      "Epoch [73/200], Train Loss: 0.5649, Val Loss: 0.5693\n",
      "Epoch [74/200], Loss: 0.5632\n",
      "Epoch [74/200], Train Loss: 0.5632, Val Loss: 0.5747\n",
      "Epoch [75/200], Loss: 0.5621\n",
      "Epoch [75/200], Train Loss: 0.5621, Val Loss: 0.5742\n",
      "Epoch [76/200], Loss: 0.5642\n",
      "Epoch [76/200], Train Loss: 0.5642, Val Loss: 0.5714\n",
      "Epoch [77/200], Loss: 0.5624\n",
      "Epoch [77/200], Train Loss: 0.5624, Val Loss: 0.5753\n",
      "Epoch [78/200], Loss: 0.5619\n",
      "Epoch [78/200], Train Loss: 0.5619, Val Loss: 0.5775\n",
      "Epoch [79/200], Loss: 0.5657\n",
      "Epoch [79/200], Train Loss: 0.5657, Val Loss: 0.5777\n",
      "Epoch [80/200], Loss: 0.5621\n",
      "Epoch [80/200], Train Loss: 0.5621, Val Loss: 0.5734\n",
      "Epoch [81/200], Loss: 0.5621\n",
      "Epoch [81/200], Train Loss: 0.5621, Val Loss: 0.5762\n",
      "Epoch [82/200], Loss: 0.5583\n",
      "Epoch [82/200], Train Loss: 0.5583, Val Loss: 0.5728\n",
      "Epoch [83/200], Loss: 0.5618\n",
      "Epoch [83/200], Train Loss: 0.5618, Val Loss: 0.5753\n",
      "Epoch [84/200], Loss: 0.5631\n",
      "Epoch [84/200], Train Loss: 0.5631, Val Loss: 0.5667\n",
      "Epoch [85/200], Loss: 0.5622\n",
      "Epoch [85/200], Train Loss: 0.5622, Val Loss: 0.5653\n",
      "Epoch [86/200], Loss: 0.5596\n",
      "Epoch [86/200], Train Loss: 0.5596, Val Loss: 0.5743\n",
      "Epoch [87/200], Loss: 0.5581\n",
      "Epoch [87/200], Train Loss: 0.5581, Val Loss: 0.5726\n",
      "Epoch [88/200], Loss: 0.5595\n",
      "Epoch [88/200], Train Loss: 0.5595, Val Loss: 0.5773\n",
      "Epoch [89/200], Loss: 0.5620\n",
      "Epoch [89/200], Train Loss: 0.5620, Val Loss: 0.5799\n",
      "Epoch [90/200], Loss: 0.5595\n",
      "Epoch [90/200], Train Loss: 0.5595, Val Loss: 0.5712\n",
      "Epoch [91/200], Loss: 0.5621\n",
      "Epoch [91/200], Train Loss: 0.5621, Val Loss: 0.5732\n",
      "Epoch [92/200], Loss: 0.5577\n",
      "Epoch [92/200], Train Loss: 0.5577, Val Loss: 0.5760\n",
      "Epoch [93/200], Loss: 0.5605\n",
      "Epoch [93/200], Train Loss: 0.5605, Val Loss: 0.5720\n",
      "Epoch [94/200], Loss: 0.5634\n",
      "Epoch [94/200], Train Loss: 0.5634, Val Loss: 0.5688\n",
      "Epoch [95/200], Loss: 0.5610\n",
      "Epoch [95/200], Train Loss: 0.5610, Val Loss: 0.5719\n",
      "Epoch [96/200], Loss: 0.5590\n",
      "Epoch [96/200], Train Loss: 0.5590, Val Loss: 0.5716\n",
      "Epoch [97/200], Loss: 0.5585\n",
      "Epoch [97/200], Train Loss: 0.5585, Val Loss: 0.5714\n",
      "Epoch [98/200], Loss: 0.5625\n",
      "Epoch [98/200], Train Loss: 0.5625, Val Loss: 0.5749\n",
      "Epoch [99/200], Loss: 0.5597\n",
      "Epoch [99/200], Train Loss: 0.5597, Val Loss: 0.5732\n",
      "Epoch [100/200], Loss: 0.5575\n",
      "Epoch [100/200], Train Loss: 0.5575, Val Loss: 0.5797\n",
      "Epoch [101/200], Loss: 0.5580\n",
      "Epoch [101/200], Train Loss: 0.5580, Val Loss: 0.5722\n",
      "Epoch [102/200], Loss: 0.5606\n",
      "Epoch [102/200], Train Loss: 0.5606, Val Loss: 0.5695\n",
      "Epoch [103/200], Loss: 0.5592\n",
      "Epoch [103/200], Train Loss: 0.5592, Val Loss: 0.5714\n",
      "Epoch [104/200], Loss: 0.5593\n",
      "Epoch [104/200], Train Loss: 0.5593, Val Loss: 0.5784\n",
      "Epoch [105/200], Loss: 0.5569\n",
      "Epoch [105/200], Train Loss: 0.5569, Val Loss: 0.5792\n",
      "Epoch [106/200], Loss: 0.5585\n",
      "Epoch [106/200], Train Loss: 0.5585, Val Loss: 0.5804\n",
      "Epoch [107/200], Loss: 0.5573\n",
      "Epoch [107/200], Train Loss: 0.5573, Val Loss: 0.5750\n",
      "Epoch [108/200], Loss: 0.5603\n",
      "Epoch [108/200], Train Loss: 0.5603, Val Loss: 0.5709\n",
      "Epoch [109/200], Loss: 0.5573\n",
      "Epoch [109/200], Train Loss: 0.5573, Val Loss: 0.5748\n",
      "Epoch [110/200], Loss: 0.5590\n",
      "Epoch [110/200], Train Loss: 0.5590, Val Loss: 0.5720\n",
      "Epoch [111/200], Loss: 0.5592\n",
      "Epoch [111/200], Train Loss: 0.5592, Val Loss: 0.5755\n",
      "Epoch [112/200], Loss: 0.5610\n",
      "Epoch [112/200], Train Loss: 0.5610, Val Loss: 0.5681\n",
      "Epoch [113/200], Loss: 0.5602\n",
      "Epoch [113/200], Train Loss: 0.5602, Val Loss: 0.5677\n",
      "Epoch [114/200], Loss: 0.5584\n",
      "Epoch [114/200], Train Loss: 0.5584, Val Loss: 0.5776\n",
      "Epoch [115/200], Loss: 0.5592\n",
      "Epoch [115/200], Train Loss: 0.5592, Val Loss: 0.5666\n",
      "Epoch [116/200], Loss: 0.5575\n",
      "Epoch [116/200], Train Loss: 0.5575, Val Loss: 0.5662\n",
      "Epoch [117/200], Loss: 0.5608\n",
      "Epoch [117/200], Train Loss: 0.5608, Val Loss: 0.5712\n",
      "Epoch [118/200], Loss: 0.5578\n",
      "Epoch [118/200], Train Loss: 0.5578, Val Loss: 0.5766\n",
      "Epoch [119/200], Loss: 0.5608\n",
      "Epoch [119/200], Train Loss: 0.5608, Val Loss: 0.5688\n",
      "Epoch [120/200], Loss: 0.5571\n",
      "Epoch [120/200], Train Loss: 0.5571, Val Loss: 0.5749\n",
      "Epoch [121/200], Loss: 0.5569\n",
      "Epoch [121/200], Train Loss: 0.5569, Val Loss: 0.5739\n",
      "Epoch [122/200], Loss: 0.5556\n",
      "Epoch [122/200], Train Loss: 0.5556, Val Loss: 0.5703\n",
      "Epoch [123/200], Loss: 0.5548\n",
      "Epoch [123/200], Train Loss: 0.5548, Val Loss: 0.5743\n",
      "Epoch [124/200], Loss: 0.5577\n",
      "Epoch [124/200], Train Loss: 0.5577, Val Loss: 0.5638\n",
      "Epoch [125/200], Loss: 0.5572\n",
      "Epoch [125/200], Train Loss: 0.5572, Val Loss: 0.5738\n",
      "Epoch [126/200], Loss: 0.5548\n",
      "Epoch [126/200], Train Loss: 0.5548, Val Loss: 0.5763\n",
      "Epoch [127/200], Loss: 0.5575\n",
      "Epoch [127/200], Train Loss: 0.5575, Val Loss: 0.5730\n",
      "Epoch [128/200], Loss: 0.5570\n",
      "Epoch [128/200], Train Loss: 0.5570, Val Loss: 0.5694\n",
      "Epoch [129/200], Loss: 0.5593\n",
      "Epoch [129/200], Train Loss: 0.5593, Val Loss: 0.5691\n",
      "Epoch [130/200], Loss: 0.5614\n",
      "Epoch [130/200], Train Loss: 0.5614, Val Loss: 0.5679\n",
      "Epoch [131/200], Loss: 0.5589\n",
      "Epoch [131/200], Train Loss: 0.5589, Val Loss: 0.5705\n",
      "Epoch [132/200], Loss: 0.5596\n",
      "Epoch [132/200], Train Loss: 0.5596, Val Loss: 0.5694\n",
      "Epoch [133/200], Loss: 0.5577\n",
      "Epoch [133/200], Train Loss: 0.5577, Val Loss: 0.5691\n",
      "Epoch [134/200], Loss: 0.5583\n",
      "Epoch [134/200], Train Loss: 0.5583, Val Loss: 0.5706\n",
      "Epoch [135/200], Loss: 0.5583\n",
      "Epoch [135/200], Train Loss: 0.5583, Val Loss: 0.5704\n",
      "Epoch [136/200], Loss: 0.5536\n",
      "Epoch [136/200], Train Loss: 0.5536, Val Loss: 0.5711\n",
      "Epoch [137/200], Loss: 0.5593\n",
      "Epoch [137/200], Train Loss: 0.5593, Val Loss: 0.5650\n",
      "Epoch [138/200], Loss: 0.5602\n",
      "Epoch [138/200], Train Loss: 0.5602, Val Loss: 0.5685\n",
      "Epoch [139/200], Loss: 0.5592\n",
      "Epoch [139/200], Train Loss: 0.5592, Val Loss: 0.5693\n",
      "Epoch [140/200], Loss: 0.5589\n",
      "Epoch [140/200], Train Loss: 0.5589, Val Loss: 0.5675\n",
      "Epoch [141/200], Loss: 0.5536\n",
      "Epoch [141/200], Train Loss: 0.5536, Val Loss: 0.5700\n",
      "Epoch [142/200], Loss: 0.5540\n",
      "Epoch [142/200], Train Loss: 0.5540, Val Loss: 0.5710\n",
      "Epoch [143/200], Loss: 0.5579\n",
      "Epoch [143/200], Train Loss: 0.5579, Val Loss: 0.5695\n",
      "Epoch [144/200], Loss: 0.5561\n",
      "Epoch [144/200], Train Loss: 0.5561, Val Loss: 0.5712\n",
      "Epoch [145/200], Loss: 0.5539\n",
      "Epoch [145/200], Train Loss: 0.5539, Val Loss: 0.5701\n",
      "Epoch [146/200], Loss: 0.5604\n",
      "Epoch [146/200], Train Loss: 0.5604, Val Loss: 0.5685\n",
      "Epoch [147/200], Loss: 0.5568\n",
      "Epoch [147/200], Train Loss: 0.5568, Val Loss: 0.5687\n",
      "Epoch [148/200], Loss: 0.5559\n",
      "Epoch [148/200], Train Loss: 0.5559, Val Loss: 0.5693\n",
      "Epoch [149/200], Loss: 0.5532\n",
      "Epoch [149/200], Train Loss: 0.5532, Val Loss: 0.5700\n",
      "Epoch [150/200], Loss: 0.5557\n",
      "Epoch [150/200], Train Loss: 0.5557, Val Loss: 0.5695\n",
      "Epoch [151/200], Loss: 0.5544\n",
      "Epoch [151/200], Train Loss: 0.5544, Val Loss: 0.5697\n",
      "Epoch [152/200], Loss: 0.5558\n",
      "Epoch [152/200], Train Loss: 0.5558, Val Loss: 0.5692\n",
      "Epoch [153/200], Loss: 0.5543\n",
      "Epoch [153/200], Train Loss: 0.5543, Val Loss: 0.5693\n",
      "Epoch [154/200], Loss: 0.5555\n",
      "Epoch [154/200], Train Loss: 0.5555, Val Loss: 0.5667\n",
      "Epoch [155/200], Loss: 0.5582\n",
      "Epoch [155/200], Train Loss: 0.5582, Val Loss: 0.5679\n",
      "Epoch [156/200], Loss: 0.5588\n",
      "Epoch [156/200], Train Loss: 0.5588, Val Loss: 0.5622\n",
      "Epoch [157/200], Loss: 0.5537\n",
      "Epoch [157/200], Train Loss: 0.5537, Val Loss: 0.5706\n",
      "Epoch [158/200], Loss: 0.5574\n",
      "Epoch [158/200], Train Loss: 0.5574, Val Loss: 0.5639\n",
      "Epoch [159/200], Loss: 0.5576\n",
      "Epoch [159/200], Train Loss: 0.5576, Val Loss: 0.5643\n",
      "Epoch [160/200], Loss: 0.5553\n",
      "Epoch [160/200], Train Loss: 0.5553, Val Loss: 0.5687\n",
      "Epoch [161/200], Loss: 0.5544\n",
      "Epoch [161/200], Train Loss: 0.5544, Val Loss: 0.5685\n",
      "Epoch [162/200], Loss: 0.5552\n",
      "Epoch [162/200], Train Loss: 0.5552, Val Loss: 0.5708\n",
      "Epoch [163/200], Loss: 0.5586\n",
      "Epoch [163/200], Train Loss: 0.5586, Val Loss: 0.5667\n",
      "Epoch [164/200], Loss: 0.5545\n",
      "Epoch [164/200], Train Loss: 0.5545, Val Loss: 0.5657\n",
      "Epoch [165/200], Loss: 0.5540\n",
      "Epoch [165/200], Train Loss: 0.5540, Val Loss: 0.5682\n",
      "Epoch [166/200], Loss: 0.5535\n",
      "Epoch [166/200], Train Loss: 0.5535, Val Loss: 0.5739\n",
      "Epoch [167/200], Loss: 0.5529\n",
      "Epoch [167/200], Train Loss: 0.5529, Val Loss: 0.5686\n",
      "Epoch [168/200], Loss: 0.5523\n",
      "Epoch [168/200], Train Loss: 0.5523, Val Loss: 0.5652\n",
      "Epoch [169/200], Loss: 0.5602\n",
      "Epoch [169/200], Train Loss: 0.5602, Val Loss: 0.5617\n",
      "Epoch [170/200], Loss: 0.5539\n",
      "Epoch [170/200], Train Loss: 0.5539, Val Loss: 0.5645\n",
      "Epoch [171/200], Loss: 0.5563\n",
      "Epoch [171/200], Train Loss: 0.5563, Val Loss: 0.5639\n",
      "Epoch [172/200], Loss: 0.5541\n",
      "Epoch [172/200], Train Loss: 0.5541, Val Loss: 0.5638\n",
      "Epoch [173/200], Loss: 0.5565\n",
      "Epoch [173/200], Train Loss: 0.5565, Val Loss: 0.5630\n",
      "Epoch [174/200], Loss: 0.5552\n",
      "Epoch [174/200], Train Loss: 0.5552, Val Loss: 0.5632\n",
      "Epoch [175/200], Loss: 0.5535\n",
      "Epoch [175/200], Train Loss: 0.5535, Val Loss: 0.5673\n",
      "Epoch [176/200], Loss: 0.5539\n",
      "Epoch [176/200], Train Loss: 0.5539, Val Loss: 0.5624\n",
      "Epoch [177/200], Loss: 0.5542\n",
      "Epoch [177/200], Train Loss: 0.5542, Val Loss: 0.5610\n",
      "Epoch [178/200], Loss: 0.5537\n",
      "Epoch [178/200], Train Loss: 0.5537, Val Loss: 0.5650\n",
      "Epoch [179/200], Loss: 0.5545\n",
      "Epoch [179/200], Train Loss: 0.5545, Val Loss: 0.5614\n",
      "Epoch [180/200], Loss: 0.5555\n",
      "Epoch [180/200], Train Loss: 0.5555, Val Loss: 0.5600\n",
      "Epoch [181/200], Loss: 0.5547\n",
      "Epoch [181/200], Train Loss: 0.5547, Val Loss: 0.5623\n",
      "Epoch [182/200], Loss: 0.5550\n",
      "Epoch [182/200], Train Loss: 0.5550, Val Loss: 0.5636\n",
      "Epoch [183/200], Loss: 0.5555\n",
      "Epoch [183/200], Train Loss: 0.5555, Val Loss: 0.5660\n",
      "Epoch [184/200], Loss: 0.5540\n",
      "Epoch [184/200], Train Loss: 0.5540, Val Loss: 0.5641\n",
      "Epoch [185/200], Loss: 0.5559\n",
      "Epoch [185/200], Train Loss: 0.5559, Val Loss: 0.5618\n",
      "Epoch [186/200], Loss: 0.5555\n",
      "Epoch [186/200], Train Loss: 0.5555, Val Loss: 0.5611\n",
      "Epoch [187/200], Loss: 0.5544\n",
      "Epoch [187/200], Train Loss: 0.5544, Val Loss: 0.5646\n",
      "Epoch [188/200], Loss: 0.5519\n",
      "Epoch [188/200], Train Loss: 0.5519, Val Loss: 0.5634\n",
      "Epoch [189/200], Loss: 0.5524\n",
      "Epoch [189/200], Train Loss: 0.5524, Val Loss: 0.5619\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m X_batch, y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X_batch)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m, in \u001b[0;36mFTTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Transformerエンコーダに通す\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 最後のトークンを取得して分類\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# [seq_len, batch_size, d_model] -> [batch_size, d_model]\u001b[39;00m\n\u001b[1;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 平均を取る\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:511\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    508\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 511\u001b[0m     output \u001b[38;5;241m=\u001b[39m mod(\n\u001b[1;32m    512\u001b[0m         output,\n\u001b[1;32m    513\u001b[0m         src_mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m    514\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m    515\u001b[0m         src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask_for_layers,\n\u001b[1;32m    516\u001b[0m     )\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    519\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:902\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    900\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[1;32m    903\u001b[0m         x\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m    905\u001b[0m     )\n\u001b[1;32m    906\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlayer_norm(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps\n\u001b[1;32m    219\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/functional.py:2900\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2892\u001b[0m         layer_norm,\n\u001b[1;32m   2893\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2898\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2899\u001b[0m     )\n\u001b[0;32m-> 2900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlayer_norm(\n\u001b[1;32m   2901\u001b[0m     \u001b[38;5;28minput\u001b[39m, normalized_shape, weight, bias, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2902\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_params=study.best_params\n",
    "model = FTTransformer(input_dim=X_train_tensor.shape[1],\n",
    "                      num_heads=best_params[\"num_heads\"],\n",
    "                      num_layers=best_params[\"num_layers\"],\n",
    "                      d_model=best_params[\"d_model\"],\n",
    "                      dropout=best_params[\"dropout\"]).to(device)\n",
    "# 最適化と訓練を実行\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_params[\"learning_rate\"])\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs=200\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_val_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    if val_loader is not None:\n",
    "        model.eval()  \n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                val_outputs = model(X_val).squeeze()\n",
    "                val_loss = criterion(val_outputs, y_val)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        model.train()  \n",
    "\n",
    "    if val_loader is not None:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "if val_losses:\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for DNN1')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.52%\n",
      "Precision: 0.4750\n",
      "Recall: 0.9528\n",
      "F1 Score: 0.6340\n",
      "Matthews Correlation Coefficient: 0.3384\n",
      "Specificity: 0.3377\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "    # 予測と確率\n",
    "    test_outputs = model(X_test_tensor).squeeze()\n",
    "    predictions = (test_outputs >= 0.5).float()\n",
    "    y_true = y_test_tensor.cpu().numpy()\n",
    "    y_pred = predictions.cpu().numpy()\n",
    "    y_prob = test_outputs.cpu().numpy()\n",
    "\n",
    "# 評価指標\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)  \n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "\n",
    "    # 混同行列（割合表示）\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2%\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix (Normalized)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ROC曲線とAUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--') \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Model ')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # Precision-Recall曲線\n",
    "    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "    plt.plot(recall_curve, precision_curve, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve ')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルと構造を保存\n",
    "torch.save(model, '../../saved_model/FT_tranformer_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
