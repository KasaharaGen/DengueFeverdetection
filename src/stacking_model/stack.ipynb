{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import optuna\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc,matthews_corrcoef, precision_recall_curve,roc_auc_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"optim_params/optim_DNN_1_params.json\", \"r\") as f:\n",
    "    DNN_1_params = json.load(f)\n",
    "\n",
    "with open(\"optim_params/optim_DNN_2_params.json\", \"r\") as f:\n",
    "    DNN_2_params = json.load(f)\n",
    "\n",
    "with open(\"optim_params/optim_DNN_3_params.json\", \"r\") as f:\n",
    "    DNN_3_params = json.load(f)\n",
    "\n",
    "with open(\"optim_params/optim_DNN_4_params.json\", \"r\") as f:\n",
    "    DNN_4_params = json.load(f)\n",
    "\n",
    "with open(\"optim_params/optim_DNN_5_params.json\", \"r\") as f:\n",
    "    DNN_5_params = json.load(f)\n",
    "\n",
    "with open(\"optim_params/optim_DNN_6_params.json\", \"r\") as f:\n",
    "    DNN_6_params = json.load(f)\n",
    "\n",
    "with open(\"optim_params/optim_DNN_7_params.json\", \"r\") as f:\n",
    "    DNN_7_params = json.load(f)\n",
    "\n",
    "with open(\"optim_params/optim_ResNet_params.json\", \"r\") as f:\n",
    "    ResNet_params = json.load(f)\n",
    "\n",
    "with open(\"optim_params/optim_FTTransformer_params.json\", \"r\") as f:\n",
    "    FTTransformer_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_1(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=DNN_1_params[\"dropout_rate\"]):\n",
    "        super(DNN_1, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.layer3 = nn.Linear(32, 16)\n",
    "        self.bn3 = nn.BatchNorm1d(16)\n",
    "        self.layer4 = nn.Linear(16, 8)\n",
    "        self.bn4 = nn.BatchNorm1d(8)\n",
    "        self.output_layer = nn.Linear(8, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.layer1(x)))  \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.layer2(x)))  \n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.bn3(self.layer3(x)))  \n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.bn4(self.layer4(x))) \n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.sigmoid(self.output_layer(x)) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_2(nn.Module):\n",
    "    def __init__(self, input_dim,dropout1=DNN_2_params[\"dropout1\"],dropout2=DNN_2_params[\"dropout2\"],dropout3=DNN_2_params[\"dropout3\"],dropout4=DNN_2_params[\"dropout4\"]):\n",
    "        super(DNN_2, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,64)\n",
    "        self.layer2 = nn.Linear(64,32)\n",
    "        self.layer3 = nn.Linear(32,16)\n",
    "        self.layer4 = nn.Linear(16,8)\n",
    "        self.output_layer = nn.Linear(8, 1)\n",
    "\n",
    "        self.bn1=nn.BatchNorm1d(64)\n",
    "        self.bn2=nn.BatchNorm1d(32)\n",
    "        self.bn3=nn.BatchNorm1d(16)\n",
    "        self.bn4=nn.BatchNorm1d(8)\n",
    "\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        self.dropout3 = nn.Dropout(dropout3)\n",
    "        self.dropout4 = nn.Dropout(dropout4)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.relu(self.bn3(self.layer3(x)))\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = torch.relu(self.bn4(self.layer4(x)))\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = torch.sigmoid(self.output_layer(x)) \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_3(nn.Module):\n",
    "    def __init__(self, input_dim,dropout1=DNN_3_params[\"dropout1\"],dropout2=DNN_3_params[\"dropout2\"]):\n",
    "        super(DNN_3, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,64)\n",
    "        self.layer2 = nn.Linear(64,32)\n",
    "        self.layer3 = nn.Linear(32, 16)\n",
    "        self.layer4 = nn.Linear(16, 8)\n",
    "        self.output_layer = nn.Linear(8, 1)\n",
    "\n",
    "        self.bn1=nn.BatchNorm1d(64)\n",
    "        self.bn2=nn.BatchNorm1d(32)\n",
    "        self.bn3=nn.BatchNorm1d(16)\n",
    "        self.bn4=nn.BatchNorm1d(8)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.layer1(x)))\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = torch.relu(self.bn3(self.layer3(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.relu(self.bn4(self.layer4(x)))\n",
    "    \n",
    "\n",
    "        x = torch.sigmoid(self.output_layer(x)) \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_4(nn.Module):\n",
    "    def __init__(self, input_dim,dropout1=DNN_4_params[\"dropout1\"],dropout2=DNN_4_params[\"dropout2\"]):\n",
    "        super(DNN_4, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,64)\n",
    "        self.layer2 = nn.Linear(64,32)\n",
    "        self.layer3 = nn.Linear(32, 16)\n",
    "        self.layer4 = nn.Linear(16, 8)\n",
    "        self.output_layer = nn.Linear(8, 1)\n",
    "\n",
    "        self.bn1=nn.BatchNorm1d(64)\n",
    "        self.bn2=nn.BatchNorm1d(32)\n",
    "        self.bn3=nn.BatchNorm1d(16)\n",
    "        self.bn4=nn.BatchNorm1d(8)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "    \n",
    "\n",
    "        x = torch.relu(self.bn3(self.layer3(x)))\n",
    "        \n",
    "\n",
    "        x = torch.relu(self.bn4(self.layer4(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.sigmoid(self.output_layer(x)) \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_5(nn.Module):\n",
    "    def __init__(self, input_dim,dropout1=DNN_5_params[\"dropout1\"],dropout2=DNN_5_params[\"dropout2\"]):\n",
    "        super(DNN_5, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,64)\n",
    "        self.layer2 = nn.Linear(64,32)\n",
    "        self.layer3 = nn.Linear(32, 16)\n",
    "        self.layer4 = nn.Linear(16, 8)\n",
    "        self.output_layer = nn.Linear(8, 1)\n",
    "\n",
    "        self.bn1=nn.BatchNorm1d(64)\n",
    "        self.bn2=nn.BatchNorm1d(32)\n",
    "        self.bn3=nn.BatchNorm1d(16)\n",
    "        self.bn4=nn.BatchNorm1d(8)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.layer1(x)))\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "        \n",
    "\n",
    "        x = torch.relu(self.bn3(self.layer3(x)))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = torch.relu(self.bn4(self.layer4(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.sigmoid(self.output_layer(x)) \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_6(nn.Module):\n",
    "    def __init__(self, input_dim,dropout1=DNN_6_params[\"dropout1\"],dropout2=DNN_6_params[\"dropout2\"]):\n",
    "        super(DNN_6, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,64)\n",
    "        self.layer2 = nn.Linear(64,32)\n",
    "        self.layer3 = nn.Linear(32, 16)\n",
    "        self.layer4 = nn.Linear(16, 8)\n",
    "        self.output_layer = nn.Linear(8, 1)\n",
    "\n",
    "        self.bn1=nn.BatchNorm1d(64)\n",
    "        self.bn2=nn.BatchNorm1d(32)\n",
    "        self.bn3=nn.BatchNorm1d(16)\n",
    "        self.bn4=nn.BatchNorm1d(8)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "    \n",
    "\n",
    "        x = torch.relu(self.bn3(self.layer3(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.relu(self.bn4(self.layer4(x)))\n",
    "        \n",
    "        x = torch.sigmoid(self.output_layer(x)) \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_7(nn.Module):\n",
    "    def __init__(self, input_dim,dropout1=DNN_7_params[\"dropout1\"],dropout2=DNN_7_params[\"dropout2\"]):\n",
    "        super(DNN_7, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,64)\n",
    "        self.layer2 = nn.Linear(64,32)\n",
    "        self.layer3 = nn.Linear(32, 16)\n",
    "        self.layer4 = nn.Linear(16, 8)\n",
    "        self.output_layer = nn.Linear(8, 1)\n",
    "\n",
    "        self.bn1=nn.BatchNorm1d(64)\n",
    "        self.bn2=nn.BatchNorm1d(32)\n",
    "        self.bn3=nn.BatchNorm1d(16)\n",
    "        self.bn4=nn.BatchNorm1d(8)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.layer1(x)))\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = torch.relu(self.bn3(self.layer3(x)))\n",
    "\n",
    "        x = torch.relu(self.bn4(self.layer4(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.sigmoid(self.output_layer(x)) \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=1, embed_dim=FTTransformer_params[\"embed_dim\"], num_heads=FTTransformer_params[\"num_heads\"], num_layers=FTTransformer_params[\"num_layers\"], dropout=FTTransformer_params[\"dropout\"]):\n",
    "        super(FTTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)  # 埋め込み層後のDropout\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "        self.output_dropout = nn.Dropout(dropout)  # 出力層前のDropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.embedding_dropout(x)  # Dropoutを埋め込み層後に適用\n",
    "        x = x.unsqueeze(1)  # [batch_size, 1, embed_dim]\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)  # 平均プーリング\n",
    "        x = self.output_dropout(x)  # Dropoutを適用\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)  # 2値分類用のシグモイド活性化\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim,dropout1,dropout2):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout1=nn.Dropout(dropout1)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(input_dim)\n",
    "        self.dropout2=nn.Dropout(dropout2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # 入力を保存 (ショートカット)\n",
    "        out = torch.relu(self.bn1(self.fc1(x)))\n",
    "        out=self.dropout1(out)\n",
    "\n",
    "        out = self.bn2(self.fc2(out))\n",
    "        out=self.dropout2(out)\n",
    "\n",
    "        out += residual  # ショートカット接続\n",
    "        return torch.relu(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_blocks=ResNet_params[\"num_blocks\"], hidden_dim=ResNet_params[\"hidden_dim\"], dropout1=ResNet_params[\"dropout1\"], dropout2=ResNet_params[\"dropout2\"]):\n",
    "        super(ResNetBinaryClassifier, self).__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[ResidualBlock(input_dim, hidden_dim, dropout1, dropout2) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.output_layer = nn.Linear(input_dim, 1)  # 出力層\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))  # 2値分類用シグモイド\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('learning_data.csv',index_col=0)\n",
    "\n",
    "X=df.drop(columns='dengue',axis=1).values\n",
    "y=df['dengue'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "\n",
    "X_train_tensor=torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor=torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor=torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor=torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバイス設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"model_params/DNN_1.pth\",\n",
    "    \"model_params/DNN_2.pth\",\n",
    "    \"model_params/DNN_3.pth\",\n",
    "    \"model_params/DNN_4.pth\",\n",
    "    \"model_params/DNN_5.pth\",\n",
    "    \"model_params/DNN_6.pth\",\n",
    "    \"model_params/DNN_7.pth\",\n",
    "    \"model_params/FTTransformer.pth\",\n",
    "    \"model_params/ResNet.pth\",\n",
    "    ]\n",
    "\n",
    "model_classes = {0: DNN_1,\n",
    "                 1: DNN_2,\n",
    "                 2: DNN_3,\n",
    "                 3: DNN_4,\n",
    "                 4: DNN_5,\n",
    "                 5: DNN_6,\n",
    "                 6: DNN_7,\n",
    "                 7:FTTransformer,\n",
    "                 8:ResNetBinaryClassifier\n",
    "                 }\n",
    "\n",
    "models=[]\n",
    "\n",
    "for i, path in enumerate(model_paths):\n",
    "    if i in model_classes:\n",
    "        model = model_classes[i](input_dim=X_train.shape[1]).to(device)\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "        model.eval()\n",
    "        models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outputs = []\n",
    "test_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        \n",
    "        train_output = model(X_train_tensor.to(device))\n",
    "        train_outputs.append(train_output)\n",
    "        \n",
    "        # テストデータの出力\n",
    "        test_output = model(X_test_tensor.to(device))\n",
    "        test_outputs.append(test_output)\n",
    "\n",
    "train_DL_features = torch.cat(train_outputs, dim=1)  \n",
    "test_DL_features = torch.cat(test_outputs, dim=1) \n",
    "\n",
    "# 出力形状の確認\n",
    "print(f\"Train DL Features Shape: {train_DL_features.shape}\")\n",
    "print(f\"Test DL Features Shape: {test_DL_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DL_features_np = train_DL_features.cpu().numpy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_features = scaler.fit_transform(train_DL_features_np.reshape(-1, train_DL_features_np.shape[-1]))\n",
    "\n",
    "# KMeans クラスタリング\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(normalized_features)\n",
    "\n",
    "# クラスタリング特徴量を修正\n",
    "cluster_features = kmeans_labels.reshape(-1, 1) \n",
    "\n",
    "# PCA（主成分分析）\n",
    "pca = PCA(n_components=6,random_state=42)\n",
    "pca_features = pca.fit_transform(normalized_features)  \n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "tsne_features = tsne.fit_transform(normalized_features) \n",
    "\n",
    "# 距離から類似度を計算\n",
    "distance_matrix = cdist(normalized_features, normalized_features, metric='euclidean')\n",
    "similarity_features = 1 / (1 + distance_matrix) \n",
    "\n",
    "# 距離から類似度の平均特徴量を生成\n",
    "similarity_features_mean = similarity_features.mean(axis=1).reshape(-1, 1) \n",
    "\n",
    "all_features = np.hstack([normalized_features,cluster_features,pca_features,tsne_features,similarity_features_mean])\n",
    "\n",
    "print(f\"all_features.shape: {all_features.shape}\")\n",
    "print(f\"train_DL_features_np.shape: {train_DL_features_np.shape}\")\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "train_standardized_features = scaler_standard.fit_transform(all_features)\n",
    "\n",
    "print(f\"train_standardized_features.shape: {train_standardized_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_DL_features_np = test_DL_features.cpu().numpy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_features = scaler.fit_transform(test_DL_features_np.reshape(-1, test_DL_features_np.shape[-1]))\n",
    "\n",
    "# KMeans クラスタリング\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(normalized_features)\n",
    "\n",
    "# クラスタリング特徴量を修正\n",
    "cluster_features = kmeans_labels.reshape(-1, 1) \n",
    "\n",
    "# PCA（主成分分析）\n",
    "pca = PCA(n_components=6,random_state=42)\n",
    "pca_features = pca.fit_transform(normalized_features)  \n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "tsne_features = tsne.fit_transform(normalized_features) \n",
    "\n",
    "# 距離から類似度を計算\n",
    "distance_matrix = cdist(normalized_features, normalized_features, metric='euclidean')\n",
    "similarity_features = 1 / (1 + distance_matrix) \n",
    "\n",
    "# 距離から類似度の平均特徴量を生成\n",
    "similarity_features_mean = similarity_features.mean(axis=1).reshape(-1, 1) \n",
    "\n",
    "all_features = np.hstack([normalized_features,cluster_features,pca_features,tsne_features,similarity_features_mean])\n",
    "\n",
    "print(f\"all_features.shape: {all_features.shape}\")\n",
    "print(f\"test_DL_features_np.shape: {train_DL_features_np.shape}\")\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "test_standardized_features = scaler_standard.fit_transform(all_features)\n",
    "\n",
    "print(f\"test_standardized_features.shape: {test_standardized_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_standardized_features, y_train, test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor=torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor=torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor=torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor=torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(test_standardized_features, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class meta_model(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, embed_dim, num_heads, num_layers, dropout):\n",
    "        super(meta_model, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)  # 埋め込み層後のDropout\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "        self.output_dropout = nn.Dropout(dropout)  # 出力層前のDropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.embedding_dropout(x)  # Dropoutを埋め込み層後に適用\n",
    "        x = x.unsqueeze(1)  # [batch_size, 1, embed_dim]\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)  # 平均プーリング\n",
    "        x = self.output_dropout(x)  # Dropoutを適用\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)  # 2値分類用のシグモイド活性化\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # ハイパーパラメータのサンプリング\n",
    "    embed_dim=trial.suggest_categorical(\"embed_dim\",[64,128,256])\n",
    "    num_heads=trial.suggest_categorical(\"num_heads\",[4,8,16])\n",
    "    num_layers=trial.suggest_categorical(\"num_layers\",[3,4,5])\n",
    "    dropout = trial.suggest_float(\"dropout_rate\", 0, 0.5, step=0.05)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-1)  \n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-1)   \n",
    "\n",
    "    # モデルの定義\n",
    "    model = meta_model(\n",
    "        input_dim=X_train_tensor.shape[1],\n",
    "        num_classes=1,\n",
    "        embed_dim=embed_dim,\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Early Stoppingの設定\n",
    "    patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # 訓練ループ\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # バリデーション評価\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                val_outputs = model(X_val).squeeze()\n",
    "                val_loss += criterion(val_outputs, y_val.squeeze()).item()\n",
    "                predictions = (val_outputs >=0.5).float()\n",
    "                val_true.extend(y_val.cpu().numpy())\n",
    "                val_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # Early Stoppingの判定\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "        # Optunaのプルーニング機能\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    mcc = matthews_corrcoef(val_true, val_pred)\n",
    "    print(f\"Final MCC: {mcc:.4f}\")\n",
    "\n",
    "    return mcc  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 1\n",
    "torch.cuda.set_device(device_id)\n",
    "device = torch.device(f\"cuda:{device_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Optunaの設定\n",
    "study = optuna.create_study(direction=\"maximize\")  \n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 結果表示\n",
    "print(\"Best Parameters: \", study.best_params)\n",
    "print(\"Best Validation F1: \", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=study.best_params\n",
    "model = meta_model(input_dim=X_train_tensor.shape[1],embed_dim=best_params[\"embed_dim\"],num_heads=best_params[\"num_heads\"],num_layers=best_params[\"num_layers\"],dropout=best_params['dropout_rate'],num_classes=1).to(device)\n",
    "\n",
    "# 最適化と訓練を実行\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_params[\"learning_rate\"],weight_decay=best_params[\"weight_decay\"])\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs=50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_val_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    if val_loader is not None:\n",
    "        model.eval()  \n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                val_outputs = model(X_val).squeeze()\n",
    "                val_loss = criterion(val_outputs, y_val.squeeze())\n",
    "                epoch_val_loss += val_loss.item()\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        model.train()  \n",
    "\n",
    "    if val_loader is not None:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "if val_losses:\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for stacking')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "    # 予測と確率\n",
    "    test_outputs = model(X_test_tensor).squeeze()\n",
    "    predictions = (test_outputs >=0.5).float()\n",
    "    y_true = y_test_tensor.cpu().numpy()\n",
    "    y_pred = predictions.cpu().numpy()\n",
    "    y_prob = test_outputs.cpu().numpy()\n",
    "\n",
    "# 評価指標\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)  \n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "\n",
    "    # 混同行列（割合表示）\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2%\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix (Normalized)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ROC曲線とAUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--') \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Model ')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # Precision-Recall曲線\n",
    "    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "    plt.plot(recall_curve, precision_curve, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve ')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
